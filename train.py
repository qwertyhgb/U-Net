
"""
UNet å›¾åƒåˆ†å‰²æ¨¡å‹è®­ç»ƒè„šæœ¬

è¯¥è„šæœ¬å®ç°äº†å®Œæ•´çš„UNetæ¨¡å‹è®­ç»ƒæµç¨‹ï¼Œä¸“é—¨ç”¨äºåŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ã€‚
UNetæ˜¯ä¸€ç§ç¼–ç å™¨-è§£ç å™¨æ¶æ„çš„å·ç§¯ç¥ç»ç½‘ç»œï¼Œåœ¨å›¾åƒåˆ†å‰²é¢†åŸŸè¡¨ç°ä¼˜å¼‚ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. æ•°æ®é›†åŠ è½½å’Œé¢„å¤„ç†ï¼ˆæ”¯æŒå¤šç§å›¾åƒæ ¼å¼ï¼‰
2. è®­ç»ƒ/éªŒè¯é›†è‡ªåŠ¨åˆ’åˆ†
3. UNetæ¨¡å‹è®­ç»ƒï¼ˆæ”¯æŒäºŒåˆ†ç±»å’Œå¤šåˆ†ç±»ï¼‰
4. æ··åˆç²¾åº¦è®­ç»ƒï¼ˆAMPï¼‰åŠ é€Ÿå’Œæ˜¾å­˜ä¼˜åŒ–
5. å®æ—¶æ€§èƒ½ç›‘æ§å’Œå¯è§†åŒ–ï¼ˆWandBé›†æˆï¼‰
6. è‡ªåŠ¨ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹å’Œæ¨¡å‹æ¢å¤
7. æ¢¯åº¦è£å‰ªå’Œå­¦ä¹ ç‡è°ƒåº¦
8. å¼‚å¸¸å¤„ç†å’Œé”™è¯¯æ¢å¤æœºåˆ¶

è®­ç»ƒç®—æ³•ç‰¹ç‚¹ï¼š
- æŸå¤±å‡½æ•°ï¼šäº¤å‰ç†µ + DiceæŸå¤±ï¼ˆå¤šåˆ†ç±»ï¼‰/ BCE + DiceæŸå¤±ï¼ˆäºŒåˆ†ç±»ï¼‰
- ä¼˜åŒ–å™¨ï¼šAdamWï¼ˆå¸¦æƒé‡è¡°å‡å’ŒAMSGradï¼‰
- å­¦ä¹ ç‡è°ƒåº¦ï¼šä½™å¼¦é€€ç«é‡å¯ï¼ˆCosineAnnealingWarmRestartsï¼‰
- æ•°æ®å¢å¼ºï¼šå›¾åƒç¼©æ”¾ã€éšæœºè£å‰ªç­‰
- æ­£åˆ™åŒ–ï¼šL2æƒé‡è¡°å‡ã€æ¢¯åº¦è£å‰ª

æŠ€æœ¯äº®ç‚¹ï¼š
1. è‡ªåŠ¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆAMPï¼‰å‡å°‘æ˜¾å­˜å ç”¨50%
2. é€šé“ä¼˜å…ˆå†…å­˜æ ¼å¼ä¼˜åŒ–GPUæ€§èƒ½
3. æ¢¯åº¦æ£€æŸ¥ç‚¹æœºåˆ¶å¤„ç†å¤§æ¨¡å‹æ˜¾å­˜ä¸è¶³
4. å®æ—¶è®­ç»ƒç›‘æ§å’Œå¯è§†åŒ–
5. æ™ºèƒ½å¼‚å¸¸å¤„ç†å’Œè‡ªåŠ¨æ¢å¤

é€‚ç”¨åœºæ™¯ï¼š
- åŒ»å­¦å›¾åƒåˆ†å‰²ï¼ˆå™¨å®˜ã€ç—…å˜åŒºåŸŸç­‰ï¼‰
- å«æ˜Ÿå›¾åƒåˆ†å‰²ï¼ˆå»ºç­‘ã€é“è·¯ç­‰ï¼‰
- ç”Ÿç‰©å›¾åƒåˆ†æï¼ˆç»†èƒåˆ†å‰²ç­‰ï¼‰
- è‡ªåŠ¨é©¾é©¶åœºæ™¯åˆ†å‰²

ä½¿ç”¨ç¤ºä¾‹ï¼š
    # åŸºç¡€è®­ç»ƒ
    python train.py --epochs 50 --batch-size 8 --learning-rate 1e-4
    
    # é«˜æ€§èƒ½è®­ç»ƒï¼ˆæ··åˆç²¾åº¦+å¤§æ‰¹æ¬¡ï¼‰
    python train.py --epochs 100 --batch-size 16 --amp --scale 0.75
    
    # ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
    python train.py --load checkpoints/checkpoint_epoch10.pth --epochs 50
"""

# ================================
# æ ‡å‡†åº“å¯¼å…¥
# ================================
import argparse  # ç”¨äºè§£æå‘½ä»¤è¡Œå‚æ•°ï¼Œæ”¯æŒå¤æ‚çš„å‚æ•°é…ç½®
import logging   # ç”¨äºè®°å½•è®­ç»ƒæ—¥å¿—ï¼Œæ”¯æŒä¸åŒçº§åˆ«çš„æ—¥å¿—è¾“å‡º
import os        # å¤„ç†æ“ä½œç³»ç»Ÿç›¸å…³æ“ä½œï¼Œå¦‚æ–‡ä»¶è·¯å¾„ã€ç¯å¢ƒå˜é‡ç­‰
import random    # éšæœºæ•°ç”Ÿæˆï¼Œç”¨äºæ•°æ®å¢å¼ºå’Œåˆå§‹åŒ–
import sys       # ç³»ç»Ÿç›¸å…³åŠŸèƒ½ï¼Œå¦‚ç¨‹åºé€€å‡ºã€å¼‚å¸¸å¤„ç†ç­‰

# ================================
# æ·±åº¦å­¦ä¹ ç›¸å…³åº“å¯¼å…¥
# ================================
import torch            # PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶æ ¸å¿ƒåº“
import torch.nn as nn   # ç¥ç»ç½‘ç»œæ¨¡å—ï¼ŒåŒ…å«å„ç§å±‚å’Œæ¿€æ´»å‡½æ•°
import torch.nn.functional as F  # ç¥ç»ç½‘ç»œå‡½æ•°åº“ï¼Œæä¾›æ— çŠ¶æ€çš„å‡½æ•°å¼æ¥å£
import torchvision.transforms as transforms        # å›¾åƒå˜æ¢å·¥å…·ï¼Œç”¨äºæ•°æ®é¢„å¤„ç†
import torchvision.transforms.functional as TF     # å›¾åƒå˜æ¢å‡½æ•°ï¼Œæä¾›åº•å±‚å˜æ¢æ“ä½œ
from torch import optim   # ä¼˜åŒ–å™¨æ¨¡å—ï¼ŒåŒ…å«å„ç§æ¢¯åº¦ä¸‹é™ç®—æ³•
from torch.utils.data import DataLoader, random_split  # æ•°æ®åŠ è½½å’Œåˆ’åˆ†å·¥å…·

# ================================
# å·¥å…·åº“å¯¼å…¥
# ================================
from pathlib import Path  # è·¯å¾„å¤„ç†å·¥å…·ï¼Œæä¾›è·¨å¹³å°è·¯å¾„æ“ä½œ
from tqdm import tqdm     # è¿›åº¦æ¡æ˜¾ç¤ºåº“ï¼Œæä¾›ç¾è§‚çš„è®­ç»ƒè¿›åº¦å¯è§†åŒ–
from typing import Tuple, Dict, Any

# ================================
# é¡¹ç›®ç›¸å…³å¯¼å…¥
# ================================
import wandb  # Weights & Biaseså®éªŒç®¡ç†å¹³å°ï¼Œç”¨äºè®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–å’Œè¶…å‚æ•°è°ƒä¼˜
from evaluate import evaluate  # æ¨¡å‹éªŒè¯è¯„ä¼°å‡½æ•°ï¼Œè®¡ç®—Diceç³»æ•°ç­‰æŒ‡æ ‡
from unet import UNet         # UNetæ¨¡å‹æ¶æ„å®šä¹‰ï¼Œç¼–ç å™¨-è§£ç å™¨åˆ†å‰²ç½‘ç»œ
from utils.data_loading import BasicDataset, CarvanaDataset  # æ•°æ®é›†åŠ è½½ç±»ï¼Œæ”¯æŒå¤šç§æ•°æ®æ ¼å¼
from utils.dice_score import dice_loss  # DiceæŸå¤±å‡½æ•°ï¼Œä¸“é—¨ç”¨äºåˆ†å‰²ä»»åŠ¡çš„æŸå¤±è®¡ç®—


# ================================
# å·¥å…·å‡½æ•°
# ================================
def _log_histograms(model: torch.nn.Module) -> Dict[str, Any]:
    """
    æ”¶é›†æ¨¡å‹æƒé‡å’Œæ¢¯åº¦çš„åˆ†å¸ƒä¿¡æ¯
    
    Args:
        model: å¾…åˆ†æçš„æ¨¡å‹
        
    Returns:
        dict: åŒ…å«æƒé‡å’Œæ¢¯åº¦åˆ†å¸ƒçš„å­—å…¸
    """
    histograms = {}
    for tag, value in model.named_parameters():
        tag = tag.replace('/', '.')  # å°†è·¯å¾„åˆ†éš”ç¬¦æ›¿æ¢ä¸ºç‚¹å·ï¼Œä¾¿äºWandBæ˜¾ç¤º
        
        # è®°å½•æƒé‡åˆ†å¸ƒç›´æ–¹å›¾ï¼ˆæ’é™¤æ— ç©·å¤§å’ŒNaNå€¼ï¼‰
        try:
            if value.grad is not None and not (torch.isinf(value) | torch.isnan(value)).any():
                # ç¡®ä¿å¼ é‡æ˜¯è¿ç»­çš„ä¸”éç¨€ç–çš„
                weight_data = value.data.cpu().contiguous()
                if not weight_data.is_sparse:
                    histograms['æƒé‡/' + tag] = wandb.Histogram(weight_data)
        except Exception:
            # å¦‚æœè®°å½•æƒé‡å¤±è´¥ï¼Œè·³è¿‡ä½†ä¸å½±å“è®­ç»ƒ
            pass
        
        # è®°å½•æ¢¯åº¦åˆ†å¸ƒç›´æ–¹å›¾ï¼ˆæ’é™¤æ— ç©·å¤§å’ŒNaNå€¼ï¼‰
        try:
            if value.grad is not None and not (torch.isinf(value.grad) | torch.isnan(value.grad)).any():
                # ç¡®ä¿æ¢¯åº¦å¼ é‡æ˜¯è¿ç»­çš„ä¸”éç¨€ç–çš„
                grad_data = value.grad.data.cpu().contiguous()
                if not grad_data.is_sparse:
                    histograms['æ¢¯åº¦/' + tag] = wandb.Histogram(grad_data)
        except Exception:
            # å¦‚æœè®°å½•æ¢¯åº¦å¤±è´¥ï¼Œè·³è¿‡ä½†ä¸å½±å“è®­ç»ƒ
            pass
    
    return histograms


class EarlyStopping:
    """æ—©åœæœºåˆ¶ç±»ï¼Œç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆ"""
    
    def __init__(self, patience: int = 10, min_delta: float = 0.001, restore_best_weights: bool = True):
        self.patience = patience
        self.min_delta = min_delta
        self.restore_best_weights = restore_best_weights
        self.best_score = None
        self.counter = 0
        self.best_weights = None
        
    def __call__(self, val_score: float, model: torch.nn.Module) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥æ—©åœ
        
        Args:
            val_score: å½“å‰éªŒè¯åˆ†æ•°
            model: æ¨¡å‹å®ä¾‹
            
        Returns:
            bool: Trueè¡¨ç¤ºåº”è¯¥åœæ­¢è®­ç»ƒ
        """
        if self.best_score is None:
            self.best_score = val_score
            self._save_weights(model)
        elif val_score >= self.best_score + self.min_delta:
            # éªŒè¯åˆ†æ•°æœ‰æ˜¾è‘—æå‡ï¼Œæ›´æ–°æœ€ä½³åˆ†æ•°
            self.best_score = val_score
            self.counter = 0
            self._save_weights(model)
        else:
            # éªŒè¯åˆ†æ•°æ²¡æœ‰æ˜¾è‘—æå‡ï¼Œå¢åŠ è®¡æ•°å™¨
            self.counter += 1
            if self.counter >= self.patience:
                if self.restore_best_weights and self.best_weights is not None:
                    model.load_state_dict(self.best_weights)
                    logging.info(f'æ¢å¤æœ€ä½³æƒé‡ï¼Œæœ€ä½³éªŒè¯åˆ†æ•°: {self.best_score:.4f}')
                return True
            
        return False
    
    def _save_weights(self, model: torch.nn.Module):
        """ä¿å­˜å½“å‰æœ€ä½³æƒé‡"""
        self.best_weights = model.state_dict().copy()


def _prepare_mask_for_logging(masks_pred: torch.Tensor, true_masks: torch.Tensor, 
                            model: torch.nn.Module) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    å‡†å¤‡ç”¨äºWandBæ—¥å¿—è®°å½•çš„æ©ç å¼ é‡
    
    Args:
        masks_pred: é¢„æµ‹æ©ç å¼ é‡
        true_masks: çœŸå®æ©ç å¼ é‡
        model: æ¨¡å‹å®ä¾‹
        
    Returns:
        tuple: (å¤„ç†åçš„é¢„æµ‹æ©ç , å¤„ç†åçš„çœŸå®æ©ç )
    """
    # å¤„ç†é¢„æµ‹æ©ç çš„ç»´åº¦é—®é¢˜ï¼Œç¡®ä¿ä¸WandBå…¼å®¹
    if model.n_classes == 1:
        # äºŒåˆ†ç±»ä»»åŠ¡ï¼šä½¿ç”¨sigmoid + é˜ˆå€¼å¤„ç†
        pred_mask = (F.sigmoid(masks_pred[0, 0]) > 0.5).float().cpu()
    else:
        # å¤šåˆ†ç±»ä»»åŠ¡ï¼šä½¿ç”¨argmaxå¤„ç†
        pred_mask = masks_pred.argmax(dim=1)[0].float().cpu()
    
    # ç¡®ä¿æ©ç å¼ é‡æ˜¯æ­£ç¡®çš„2Dæ ¼å¼ç”¨äºWandB
    if pred_mask.dim() > 2:
        pred_mask = pred_mask.squeeze()
    if pred_mask.dim() < 2:
        pred_mask = pred_mask.unsqueeze(0)
        
    # ç¡®ä¿çœŸå®æ©ç ä¹Ÿæ˜¯2Dæ ¼å¼
    true_mask = true_masks[0].float().cpu()
    if true_mask.dim() > 2:
        true_mask = true_mask.squeeze()
    if true_mask.dim() < 2:
        true_mask = true_mask.unsqueeze(0)
    
    return pred_mask, true_mask


# ================================
# å…¨å±€é…ç½®ç±»
# ================================
class Config:
    """
    å…¨å±€é…ç½®ç±»ï¼Œé›†ä¸­ç®¡ç†é¡¹ç›®é…ç½®å‚æ•°
    
    è¯¥ç±»é‡‡ç”¨é›†ä¸­å¼é…ç½®ç®¡ç†ï¼Œä¾¿äºå‚æ•°è°ƒä¼˜å’Œç»´æŠ¤ã€‚
    æ‰€æœ‰é…ç½®å‚æ•°éƒ½å®šä¹‰ä¸ºç±»å±æ€§ï¼Œå¯ä»¥åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­ç»Ÿä¸€è®¿é—®ã€‚
    
    é…ç½®åˆ†ç±»ï¼š
    1. æ•°æ®è·¯å¾„é…ç½®ï¼šå®šä¹‰æ•°æ®é›†ã€æ£€æŸ¥ç‚¹çš„å­˜å‚¨ä½ç½®
    2. è®­ç»ƒå‚æ•°é…ç½®ï¼šæ§åˆ¶è®­ç»ƒè¿‡ç¨‹çš„è¶…å‚æ•°
    3. ç¡¬ä»¶èµ„æºé…ç½®ï¼šä¼˜åŒ–å¤šæ ¸CPUå’ŒGPUä½¿ç”¨æ•ˆç‡
    
    è®¾è®¡åŸåˆ™ï¼š
    - å•ä¸€èŒè´£ï¼šæ¯ä¸ªé…ç½®é¡¹éƒ½æœ‰æ˜ç¡®çš„ä½œç”¨
    - å¯æ‰©å±•æ€§ï¼šæ˜“äºæ·»åŠ æ–°çš„é…ç½®å‚æ•°
    - å¯ç»´æŠ¤æ€§ï¼šé›†ä¸­ç®¡ç†ï¼Œä¾¿äºæ‰¹é‡ä¿®æ”¹
    """
    
    # ================================
    # æ•°æ®ç›¸å…³è·¯å¾„é…ç½®
    # ================================
    DATA_DIR = Path('./data')          # æ•°æ®æ ¹ç›®å½•ï¼Œå­˜å‚¨æ‰€æœ‰è®­ç»ƒæ•°æ®
    IMG_DIR = DATA_DIR / 'imgs'        # è®­ç»ƒå›¾ç‰‡å­˜å‚¨è·¯å¾„ï¼Œæ”¯æŒJPGã€PNGç­‰æ ¼å¼
    MASK_DIR = DATA_DIR / 'masks'      # æ ‡æ³¨æ©ç å­˜å‚¨è·¯å¾„ï¼Œä¸å›¾ç‰‡ä¸€ä¸€å¯¹åº”
    CHECKPOINT_DIR = Path('./checkpoints')  # æ¨¡å‹æ£€æŸ¥ç‚¹ä¿å­˜è·¯å¾„ï¼Œç”¨äºæ–­ç‚¹ç»­è®­
    
    # ================================
    # è®­ç»ƒç›¸å…³å‚æ•°é…ç½®
    # ================================
    RANDOM_SEED = 42        # éšæœºæ•°ç§å­ï¼Œç¡®ä¿å®éªŒå¯é‡å¤æ€§
    VAL_INTERVAL = 0.2     # éªŒè¯é—´éš”æ¯”ä¾‹ï¼ˆæ¯è®­ç»ƒå¤šå°‘è½®è¿›è¡Œä¸€æ¬¡éªŒè¯ï¼‰
    PATIENCE = 10          # æ—©åœè€å¿ƒå€¼ï¼ˆè¿ç»­å¤šå°‘è½®éªŒè¯æŒ‡æ ‡ä¸æå‡åˆ™åœæ­¢ï¼‰
    MIN_DELTA = 0.001      # æ—©åœæœ€å°æ”¹è¿›é˜ˆå€¼
    
    # ================================
    # ç¡¬ä»¶èµ„æºç›¸å…³é…ç½®
    # ================================
    NUM_WORKERS = min(os.cpu_count(), 8)  # æ•°æ®åŠ è½½çº¿ç¨‹æ•°ï¼Œé¿å…CPUè¿‡è½½
    PIN_MEMORY = torch.cuda.is_available()  # GPUè®­ç»ƒæ—¶å¯ç”¨é”é¡µå†…å­˜ï¼ŒåŠ é€Ÿæ•°æ®ä¼ è¾“
    PREFETCH_FACTOR = 2  # é¢„åŠ è½½æ‰¹æ¬¡æ•°ï¼Œå¹³è¡¡å†…å­˜å ç”¨å’ŒåŠ è½½é€Ÿåº¦


def train_model(
        model: torch.nn.Module,
        device: torch.device,
        epochs: int = 5,
        batch_size: int = 1,
        learning_rate: float = 1e-5,
        val_percent: float = 0.1,
        save_checkpoint: bool = True,
        img_scale: float = 0.5,
        amp: bool = False,
        weight_decay: float = 1e-8,
        momentum: float = 0.999,
        gradient_clipping: float = 1.0,
        accumulate_grad_batches: int = 1,  # æ¢¯åº¦ç´¯ç§¯æ‰¹æ¬¡æ•°
):
    """
    UNetæ¨¡å‹è®­ç»ƒçš„ä¸»å‡½æ•°ï¼Œå®ç°å®Œæ•´çš„è®­ç»ƒæµç¨‹

    è¯¥å‡½æ•°æ˜¯è®­ç»ƒè„šæœ¬çš„æ ¸å¿ƒï¼Œå®ç°äº†ä»æ•°æ®åŠ è½½åˆ°æ¨¡å‹ä¿å­˜çš„å®Œæ•´è®­ç»ƒæµç¨‹ã€‚
    æ”¯æŒå¤šç§è®­ç»ƒç­–ç•¥å’Œä¼˜åŒ–æŠ€æœ¯ï¼Œç¡®ä¿è®­ç»ƒè¿‡ç¨‹çš„ç¨³å®šæ€§å’Œæ•ˆç‡ã€‚
    
    ================================
    è®­ç»ƒæµç¨‹æ¦‚è¿°ï¼š
    ================================
    1. æ•°æ®é›†åŠ è½½å’Œé¢„å¤„ç†
       - è‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨åˆé€‚çš„æ•°æ®é›†ç±»ï¼ˆCarvanaDatasetæˆ–BasicDatasetï¼‰
       - æŒ‰æ¯”ä¾‹åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
       - é…ç½®é«˜æ•ˆçš„æ•°æ®åŠ è½½å™¨
    
    2. è®­ç»ƒç¯å¢ƒåˆå§‹åŒ–
       - åˆå§‹åŒ–WandBå®éªŒè·Ÿè¸ª
       - é…ç½®ä¼˜åŒ–å™¨ã€æŸå¤±å‡½æ•°å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨
       - è®¾ç½®æ··åˆç²¾åº¦è®­ç»ƒï¼ˆAMPï¼‰ç¯å¢ƒ
    
    3. è®­ç»ƒå¾ªç¯æ‰§è¡Œ
       - å‰å‘ä¼ æ’­ï¼šè®¡ç®—é¢„æµ‹ç»“æœå’ŒæŸå¤±
       - åå‘ä¼ æ’­ï¼šè®¡ç®—æ¢¯åº¦å¹¶æ›´æ–°æ¨¡å‹å‚æ•°
       - å®šæœŸéªŒè¯ï¼šè¯„ä¼°æ¨¡å‹æ€§èƒ½å¹¶è°ƒæ•´å­¦ä¹ ç‡
       - å®æ—¶ç›‘æ§ï¼šè®°å½•è®­ç»ƒæŒ‡æ ‡å’Œå¯è§†åŒ–ç»“æœ
    
    4. æ¨¡å‹ä¿å­˜å’Œæ¢å¤
       - è‡ªåŠ¨ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹
       - æ”¯æŒä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
    
    ================================
    å‚æ•°è¯¦ç»†è¯´æ˜ï¼š
    ================================
    Args:
        model (torch.nn.Module): å¾…è®­ç»ƒçš„UNetæ¨¡å‹å®ä¾‹
            - å¿…é¡»æ˜¯UNetç±»çš„å®ä¾‹ï¼ŒåŒ…å«n_channelså’Œn_classeså±æ€§
            - æ¨¡å‹åº”è¯¥å·²ç»ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ä¸Š
            - æ”¯æŒé¢„è®­ç»ƒæƒé‡åŠ è½½
        
        device (torch.device): è®­ç»ƒè®¾å¤‡
            - 'cuda': ä½¿ç”¨GPUè®­ç»ƒï¼Œéœ€è¦CUDAæ”¯æŒ
            - 'cpu': ä½¿ç”¨CPUè®­ç»ƒï¼Œé€Ÿåº¦è¾ƒæ…¢ä½†å…¼å®¹æ€§å¥½
            - 'mps': Apple Siliconè®¾å¤‡ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
        
        epochs (int, optional): æ€»è®­ç»ƒè½®æ•°. é»˜è®¤å€¼: 5
            - æ¯è½®éå†æ•´ä¸ªè®­ç»ƒé›†ä¸€æ¬¡
            - å»ºè®®å€¼ï¼šå°æ•°æ®é›†50-100è½®ï¼Œå¤§æ•°æ®é›†20-50è½®
            - è¿‡å°‘å¯èƒ½å¯¼è‡´æ¬ æ‹Ÿåˆï¼Œè¿‡å¤šå¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆ
        
        batch_size (int, optional): æ‰¹æ¬¡å¤§å°. é»˜è®¤å€¼: 1
            - æ¯æ‰¹æ¬¡å¤„ç†çš„æ ·æœ¬æ•°ï¼Œç›´æ¥å½±å“è®­ç»ƒé€Ÿåº¦å’Œæ˜¾å­˜å ç”¨
            - GPUæ˜¾å­˜å»ºè®®ï¼š8GBæ˜¾å­˜å¯ç”¨batch_size=4-8ï¼Œ16GBå¯ç”¨8-16
            - è¿‡å°å½±å“è®­ç»ƒæ•ˆç‡ï¼Œè¿‡å¤§å¯èƒ½å¯¼è‡´æ˜¾å­˜æº¢å‡º
        
        learning_rate (float, optional): åˆå§‹å­¦ä¹ ç‡. é»˜è®¤å€¼: 1e-5
            - æ§åˆ¶æ¨¡å‹å‚æ•°æ›´æ–°çš„æ­¥é•¿
            - å»ºè®®èŒƒå›´ï¼š1e-4 åˆ° 1e-6
            - è¿‡é«˜å¯èƒ½å¯¼è‡´è®­ç»ƒä¸ç¨³å®šï¼Œè¿‡ä½å¯èƒ½å¯¼è‡´æ”¶æ•›ç¼“æ…¢
        
        val_percent (float, optional): éªŒè¯é›†æ¯”ä¾‹. é»˜è®¤å€¼: 0.1
            - éªŒè¯é›†å æ€»æ•°æ®é›†çš„æ¯”ä¾‹ï¼ŒèŒƒå›´[0, 1]
            - 0.1è¡¨ç¤º10%æ•°æ®ç”¨äºéªŒè¯ï¼Œ90%ç”¨äºè®­ç»ƒ
            - å»ºè®®å€¼ï¼šå°æ•°æ®é›†0.2-0.3ï¼Œå¤§æ•°æ®é›†0.1-0.2
        
        save_checkpoint (bool, optional): æ˜¯å¦ä¿å­˜æ£€æŸ¥ç‚¹. é»˜è®¤å€¼: True
            - True: æ¯è½®ç»“æŸåä¿å­˜æ¨¡å‹çŠ¶æ€ï¼Œæ”¯æŒæ–­ç‚¹ç»­è®­
            - False: ä¸ä¿å­˜æ£€æŸ¥ç‚¹ï¼ŒèŠ‚çœç£ç›˜ç©ºé—´
        
        img_scale (float, optional): å›¾åƒç¼©æ”¾æ¯”ä¾‹. é»˜è®¤å€¼: 0.5
            - æ§åˆ¶è¾“å…¥å›¾åƒçš„å°ºå¯¸ï¼ŒèŒƒå›´(0, 1]
            - 0.5è¡¨ç¤ºå°†å›¾åƒå°ºå¯¸ç¼©å°åˆ°åŸæ¥çš„50%
            - è¾ƒå°çš„å€¼å¯ä»¥å‡å°‘æ˜¾å­˜å ç”¨ï¼Œä½†å¯èƒ½å½±å“åˆ†å‰²ç²¾åº¦
        
        amp (bool, optional): æ˜¯å¦å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ. é»˜è®¤å€¼: False
            - True: ä½¿ç”¨FP16ç²¾åº¦è®­ç»ƒï¼Œå¯å‡å°‘50%æ˜¾å­˜å ç”¨
            - False: ä½¿ç”¨FP32ç²¾åº¦è®­ç»ƒï¼Œæ•°å€¼ç¨³å®šæ€§æ›´å¥½
            - å»ºè®®åœ¨æ˜¾å­˜ä¸è¶³æ—¶å¯ç”¨
        
        weight_decay (float, optional): L2æ­£åˆ™åŒ–ç³»æ•°. é»˜è®¤å€¼: 1e-8
            - é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ­£åˆ™åŒ–é¡¹
            - å»ºè®®èŒƒå›´ï¼š1e-8 åˆ° 1e-4
            - è¿‡å¤§ä¼šå½±å“æ¨¡å‹å­¦ä¹ èƒ½åŠ›ï¼Œè¿‡å°å¯èƒ½æ— æ³•é˜²æ­¢è¿‡æ‹Ÿåˆ
        
        momentum (float, optional): åŠ¨é‡å› å­. é»˜è®¤å€¼: 0.999
            - ä¼˜åŒ–å™¨çš„åŠ¨é‡å‚æ•°ï¼Œå½±å“å‚æ•°æ›´æ–°æ–¹å‘
            - ä»…åœ¨ä½¿ç”¨SGDä¼˜åŒ–å™¨æ—¶æœ‰æ•ˆ
            - å»ºè®®èŒƒå›´ï¼š0.9 åˆ° 0.999
        
        gradient_clipping (float, optional): æ¢¯åº¦è£å‰ªé˜ˆå€¼. é»˜è®¤å€¼: 1.0
            - é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸çš„æŠ€æœ¯
            - å½“æ¢¯åº¦èŒƒæ•°è¶…è¿‡æ­¤å€¼æ—¶è¿›è¡Œè£å‰ª
            - å»ºè®®èŒƒå›´ï¼š0.5 åˆ° 2.0
    
    Returns:
        None: è¯¥å‡½æ•°ä¸è¿”å›å€¼ï¼Œè®­ç»ƒç»“æœé€šè¿‡æ£€æŸ¥ç‚¹æ–‡ä»¶å’ŒWandBè®°å½•
    
    Raises:
        RuntimeError: å½“æ•°æ®é›†åŠ è½½å¤±è´¥æ—¶æŠ›å‡º
        AssertionError: å½“æ¨¡å‹è¾“å…¥é€šé“æ•°ä¸å›¾åƒé€šé“æ•°ä¸åŒ¹é…æ—¶æŠ›å‡º
        torch.cuda.OutOfMemoryError: å½“GPUæ˜¾å­˜ä¸è¶³æ—¶æŠ›å‡º
    
    ================================
    è®­ç»ƒç­–ç•¥è¯´æ˜ï¼š
    ================================
    
    1. æŸå¤±å‡½æ•°ç»„åˆï¼š
       - äºŒåˆ†ç±»ä»»åŠ¡ï¼šBCEæŸå¤± + DiceæŸå¤±
       - å¤šåˆ†ç±»ä»»åŠ¡ï¼šäº¤å‰ç†µæŸå¤± + DiceæŸå¤±
       - DiceæŸå¤±ä¸“é—¨ä¼˜åŒ–åˆ†å‰²ä»»åŠ¡çš„é‡å åº¦æŒ‡æ ‡
    
    2. ä¼˜åŒ–å™¨é…ç½®ï¼š
       - ä½¿ç”¨AdamWä¼˜åŒ–å™¨ï¼Œç»“åˆäº†Adamå’Œæƒé‡è¡°å‡çš„ä¼˜åŠ¿
       - å¯ç”¨AMSGradå˜ä½“ï¼Œæä¾›æ›´ç¨³å®šçš„è®­ç»ƒè¿‡ç¨‹
       - è‡ªåŠ¨æƒé‡è¡°å‡é˜²æ­¢è¿‡æ‹Ÿåˆ
    
    3. å­¦ä¹ ç‡è°ƒåº¦ï¼š
       - ä½¿ç”¨ä½™å¼¦é€€ç«é‡å¯ç­–ç•¥
       - åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡
       - é¿å…å­¦ä¹ ç‡è¿‡å°å¯¼è‡´çš„æ”¶æ•›åœæ»
    
    4. æ··åˆç²¾åº¦è®­ç»ƒï¼š
       - ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦ï¼ˆAMPï¼‰æŠ€æœ¯
       - åœ¨ä¿æŒæ•°å€¼ç¨³å®šæ€§çš„åŒæ—¶æå‡è®­ç»ƒé€Ÿåº¦
       - ç‰¹åˆ«é€‚ç”¨äºå¤§æ¨¡å‹è®­ç»ƒ
    
    ================================
    æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯ï¼š
    ================================
    
    1. å†…å­˜ä¼˜åŒ–ï¼š
       - é€šé“ä¼˜å…ˆå†…å­˜æ ¼å¼ï¼ˆchannels_lastï¼‰æå‡GPUæ€§èƒ½
       - æ¢¯åº¦ç´¯ç§¯å‡å°‘æ˜¾å­˜å ç”¨
       - é”é¡µå†…å­˜åŠ é€ŸCPU-GPUæ•°æ®ä¼ è¾“
    
    2. è®¡ç®—ä¼˜åŒ–ï¼š
       - è‡ªåŠ¨æ··åˆç²¾åº¦å‡å°‘è®¡ç®—é‡
       - æ•°æ®å¹¶è¡ŒåŠ è½½æå‡I/Oæ•ˆç‡
       - æ¢¯åº¦æ£€æŸ¥ç‚¹æœºåˆ¶å¤„ç†å¤§æ¨¡å‹
    
    3. ç›‘æ§å’Œè°ƒè¯•ï¼š
       - å®æ—¶æŸå¤±å’ŒæŒ‡æ ‡è®°å½•
       - æƒé‡å’Œæ¢¯åº¦åˆ†å¸ƒå¯è§†åŒ–
       - è®­ç»ƒè¿‡ç¨‹å›¾åƒå’Œé¢„æµ‹ç»“æœå±•ç¤º
    
    ================================
    ä½¿ç”¨ç¤ºä¾‹ï¼š
    ================================
    
    ```python
    # åŸºç¡€è®­ç»ƒç¤ºä¾‹
    model = UNet(n_channels=3, n_classes=2)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    train_model(
        model=model,
        device=device,
        epochs=50,
        batch_size=8,
        learning_rate=1e-4,
        val_percent=0.2,
        amp=True
    )
    
    # é«˜æ€§èƒ½è®­ç»ƒç¤ºä¾‹
    train_model(
        model=model,
        device=device,
        epochs=100,
        batch_size=16,
        learning_rate=1e-4,
        img_scale=0.75,
        amp=True,
        weight_decay=1e-5
    )
    ```
    
    ================================
    æ³¨æ„äº‹é¡¹å’Œæœ€ä½³å®è·µï¼š
    ================================
    
    1. æ•°æ®å‡†å¤‡ï¼š
       - ç¡®ä¿å›¾ç‰‡å’Œæ©ç æ–‡ä»¶ä¸€ä¸€å¯¹åº”
       - æ£€æŸ¥å›¾ç‰‡æ ¼å¼å’Œé€šé“æ•°æ˜¯å¦ä¸€è‡´
       - éªŒè¯æ©ç æ ‡ç­¾å€¼æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
    
    2. ç¡¬ä»¶é…ç½®ï¼š
       - GPUè®­ç»ƒæ—¶ç¡®ä¿CUDAç‰ˆæœ¬å…¼å®¹
       - æ ¹æ®æ˜¾å­˜å¤§å°è°ƒæ•´batch_size
       - ä½¿ç”¨SSDå­˜å‚¨æå‡æ•°æ®åŠ è½½é€Ÿåº¦
    
    3. è¶…å‚æ•°è°ƒä¼˜ï¼š
       - å­¦ä¹ ç‡æ˜¯æœ€é‡è¦çš„è¶…å‚æ•°ï¼Œéœ€è¦ä»”ç»†è°ƒæ•´
       - æ‰¹æ¬¡å¤§å°å½±å“è®­ç»ƒç¨³å®šæ€§å’Œæ”¶æ•›é€Ÿåº¦
       - éªŒè¯é›†æ¯”ä¾‹å½±å“æ¨¡å‹æ³›åŒ–èƒ½åŠ›è¯„ä¼°
    
    4. è®­ç»ƒç›‘æ§ï¼š
       - å®šæœŸæ£€æŸ¥è®­ç»ƒæŸå¤±å’ŒéªŒè¯æŒ‡æ ‡
       - å…³æ³¨è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆç°è±¡
       - ä½¿ç”¨WandBç­‰å·¥å…·è¿›è¡Œå¯è§†åŒ–åˆ†æ
    
    5. å¼‚å¸¸å¤„ç†ï¼š
       - æ˜¾å­˜æº¢å‡ºæ—¶è‡ªåŠ¨å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
       - è®­ç»ƒä¸­æ–­æ—¶å¯ä»¥ä»æ£€æŸ¥ç‚¹æ¢å¤
       - ç½‘ç»œå¼‚å¸¸æ—¶è‡ªåŠ¨é‡è¯•æœºåˆ¶
    """
    # ================================
    # 1. æ•°æ®é›†åˆ›å»ºå’ŒåŠ è½½
    # ================================
    # ä¼˜å…ˆå°è¯•ä½¿ç”¨CarvanaDatasetï¼Œå¦‚æœå¤±è´¥åˆ™å›é€€åˆ°BasicDataset
    # CarvanaDatasetä¸“é—¨ä¸ºCarvanaæ±½è½¦åˆ†å‰²æ•°æ®é›†ä¼˜åŒ–ï¼ŒåŒ…å«ç‰¹å®šçš„æ©ç åç¼€å¤„ç†
    # BasicDatasetæ˜¯é€šç”¨æ•°æ®é›†ç±»ï¼Œæ”¯æŒå„ç§å›¾åƒåˆ†å‰²ä»»åŠ¡
    try:
        dataset = CarvanaDataset(Config.IMG_DIR, Config.MASK_DIR, img_scale)
        logging.info(f'æˆåŠŸåŠ è½½CarvanaDatasetï¼Œå…±{len(dataset)}ä¸ªæ ·æœ¬')
    except (AssertionError, RuntimeError, IndexError) as e:
        logging.warning(f'CarvanaDatasetåŠ è½½å¤±è´¥: {e}ï¼Œå›é€€åˆ°BasicDataset')
        dataset = BasicDataset(Config.IMG_DIR, Config.MASK_DIR, img_scale)
        logging.info(f'æˆåŠŸåŠ è½½BasicDatasetï¼Œå…±{len(dataset)}ä¸ªæ ·æœ¬')

    # ================================
    # 2. è®­ç»ƒé›†å’ŒéªŒè¯é›†åˆ’åˆ†
    # ================================
    # æŒ‰ç…§æŒ‡å®šæ¯”ä¾‹å°†æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†
    # ä½¿ç”¨å›ºå®šéšæœºç§å­ç¡®ä¿æ¯æ¬¡è¿è¡Œçš„æ•°æ®åˆ’åˆ†ç»“æœä¸€è‡´
    n_val = int(len(dataset) * val_percent)  # è®¡ç®—éªŒè¯é›†æ ·æœ¬æ•°é‡
    n_train = len(dataset) - n_val           # è®¡ç®—è®­ç»ƒé›†æ ·æœ¬æ•°é‡
    
    # ä½¿ç”¨random_splitè¿›è¡Œæ•°æ®åˆ’åˆ†ï¼Œç¡®ä¿å¯é‡å¤æ€§
    # generatorå‚æ•°ä½¿ç”¨å›ºå®šç§å­ï¼Œä¿è¯å®éªŒçš„å¯é‡å¤æ€§
    train_set, val_set = random_split(
        dataset, 
        [n_train, n_val], 
        generator=torch.Generator().manual_seed(0)
    )
    
    logging.info(f'æ•°æ®é›†åˆ’åˆ†å®Œæˆï¼šè®­ç»ƒé›†{n_train}ä¸ªæ ·æœ¬ï¼ŒéªŒè¯é›†{n_val}ä¸ªæ ·æœ¬')

    # ================================
    # 3. æ•°æ®åŠ è½½å™¨é…ç½®å’Œåˆ›å»º
    # ================================
    # åŠ¨æ€é…ç½®æ•°æ®åŠ è½½å™¨å‚æ•°ï¼Œæ ¹æ®è®¾å¤‡å’Œæ‰¹æ¬¡å¤§å°ä¼˜åŒ–
    num_workers = min(Config.NUM_WORKERS, batch_size * 2) if batch_size > 1 else Config.NUM_WORKERS
    
    # æ ¹æ®è®¾å¤‡ç±»å‹ä¼˜åŒ–æ•°æ®åŠ è½½å™¨é…ç½®
    loader_args = dict(
        batch_size=batch_size,                    # æ‰¹æ¬¡å¤§å°ï¼Œæ ¹æ®æ˜¾å­˜è°ƒæ•´
        num_workers=num_workers,                 # åŠ¨æ€è°ƒæ•´æ•°æ®åŠ è½½çº¿ç¨‹æ•°
        pin_memory=device.type == 'cuda',        # ä»…åœ¨CUDAè®¾å¤‡ä¸Šå¯ç”¨é”é¡µå†…å­˜
        prefetch_factor=Config.PREFETCH_FACTOR if num_workers > 0 else None,  # é¢„åŠ è½½æ‰¹æ¬¡æ•°
        persistent_workers=num_workers > 0,      # ä»…åœ¨å¤šè¿›ç¨‹æ—¶ä¿æŒworkerå­˜æ´»
        multiprocessing_context='spawn' if os.name == 'nt' and num_workers > 0 else None  # Windowså…¼å®¹æ€§
    )
    
    # åˆ›å»ºå›ºå®šéšæœºç§å­çš„ç”Ÿæˆå™¨ï¼Œç¡®ä¿è®­ç»ƒè¿‡ç¨‹çš„å¯é‡å¤æ€§
    g = torch.Generator()
    g.manual_seed(Config.RANDOM_SEED)
    
    # åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_set,
        shuffle=True,          # è®­ç»ƒæ—¶æ‰“ä¹±æ•°æ®é¡ºåºï¼Œæé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›
        drop_last=True,        # ä¸¢å¼ƒä¸å®Œæ•´çš„æœ€åä¸€æ‰¹ï¼Œé¿å…æ‰¹æ¬¡å¤§å°ä¸ä¸€è‡´å½±å“è®­ç»ƒç¨³å®šæ€§
        generator=g,           # ä½¿ç”¨å›ºå®šç§å­çš„ç”Ÿæˆå™¨
        **loader_args
    )
    
    # åˆ›å»ºéªŒè¯æ•°æ®åŠ è½½å™¨
    val_loader = DataLoader(
        val_set,
        shuffle=False,         # éªŒè¯æ—¶ä¸æ‰“ä¹±æ•°æ®ï¼Œç¡®ä¿è¯„ä¼°ç»“æœçš„ä¸€è‡´æ€§
        drop_last=True,        # åŒæ ·ä¸¢å¼ƒä¸å®Œæ•´çš„æ‰¹æ¬¡
        **loader_args
    )

    logging.info(f'æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆï¼šè®­ç»ƒæ‰¹æ¬¡{len(train_loader)}ä¸ªï¼ŒéªŒè¯æ‰¹æ¬¡{len(val_loader)}ä¸ª')

    # ================================
    # 4. å®éªŒè·Ÿè¸ªå’Œæ—¥å¿—åˆå§‹åŒ–
    # ================================
    # åˆå§‹åŒ–WandBå®éªŒè·Ÿè¸ªï¼Œç”¨äºè®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–å’Œè¶…å‚æ•°ç®¡ç†
    # resume='allow': å…è®¸æ¢å¤ä¸­æ–­çš„å®éªŒ
    # anonymous='must': å…è®¸åŒ¿åä½¿ç”¨WandB
    experiment = wandb.init(
        project='U-Net', 
        resume='allow', 
        anonymous='must',
        name=f'unetè®­ç»ƒ_{epochs}è½®æ¬¡_æ‰¹æ¬¡{batch_size}'
    )
    
    # è®°å½•è®­ç»ƒé…ç½®å‚æ•°åˆ°WandB
    experiment.config.update(
        dict(
            epochs=epochs, 
            batch_size=batch_size, 
            learning_rate=learning_rate,
            val_percent=val_percent, 
            save_checkpoint=save_checkpoint, 
            img_scale=img_scale, 
            amp=amp,
            weight_decay=weight_decay,
            gradient_clipping=gradient_clipping
        )
    )

    # æ‰“å°è¯¦ç»†çš„è®­ç»ƒå‚æ•°ä¿¡æ¯
    logging.info(f'''
    ================================
    è®­ç»ƒé…ç½®ä¿¡æ¯
    ================================
    è®­ç»ƒè½®æ•°:           {epochs}
    æ‰¹æ¬¡å¤§å°:           {batch_size}
    å­¦ä¹ ç‡:             {learning_rate}
    è®­ç»ƒé›†å¤§å°:         {n_train}
    éªŒè¯é›†å¤§å°:         {n_val}
    éªŒè¯é›†æ¯”ä¾‹:         {val_percent:.1%}
    æ˜¯å¦ä¿å­˜æ£€æŸ¥ç‚¹:     {save_checkpoint}
    è®­ç»ƒè®¾å¤‡:           {device.type}
    å›¾ç‰‡ç¼©æ”¾æ¯”ä¾‹:       {img_scale}
    æ··åˆç²¾åº¦è®­ç»ƒ:       {amp}
    æƒé‡è¡°å‡:           {weight_decay}
    æ¢¯åº¦è£å‰ªé˜ˆå€¼:       {gradient_clipping}
    ================================
    ''')

    # ================================
    # 5. è®­ç»ƒç»„ä»¶åˆå§‹åŒ–
    # ================================
    
    # 5.1 ä¼˜åŒ–å™¨é…ç½®
    # ä½¿ç”¨AdamWä¼˜åŒ–å™¨ï¼Œç»“åˆäº†Adamçš„è‡ªé€‚åº”å­¦ä¹ ç‡å’Œæƒé‡è¡°å‡çš„ä¼˜åŠ¿
    # AdamWç›¸æ¯”Adamæœ‰æ›´å¥½çš„æ³›åŒ–æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨æ·±åº¦å­¦ä¹ ä»»åŠ¡ä¸­
    optimizer = optim.AdamW(
        model.parameters(),
        lr=learning_rate,           # åˆå§‹å­¦ä¹ ç‡
        weight_decay=weight_decay,  # L2æ­£åˆ™åŒ–ç³»æ•°ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
        amsgrad=True               # å¯ç”¨AMSGradå˜ä½“ï¼Œæä¾›æ›´ç¨³å®šçš„è®­ç»ƒè¿‡ç¨‹
    )
    
    # 5.2 å­¦ä¹ ç‡è°ƒåº¦å™¨é…ç½®
    # ä½¿ç”¨ä½™å¼¦é€€ç«é‡å¯ç­–ç•¥ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡
    # è¿™ç§ç­–ç•¥å¯ä»¥åœ¨è®­ç»ƒåæœŸæä¾›æ›´å¥½çš„æ”¶æ•›æ€§èƒ½
    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
        optimizer,
        T_0=epochs // 3,                    # ç¬¬ä¸€æ¬¡é‡å¯çš„å‘¨æœŸé•¿åº¦
        T_mult=2,                          # æ¯æ¬¡é‡å¯åå‘¨æœŸé•¿åº¦ç¿»å€
        eta_min=learning_rate * 1e-3       # æœ€å°å­¦ä¹ ç‡ï¼Œé˜²æ­¢å­¦ä¹ ç‡è¿‡å°
    )
    
    # 5.3 æ··åˆç²¾åº¦è®­ç»ƒç¼©æ”¾å™¨
    # ç”¨äºæ··åˆç²¾åº¦è®­ç»ƒçš„æ¢¯åº¦ç¼©æ”¾ï¼Œç¡®ä¿è®­ç»ƒç¨³å®šæ€§
    # å½“ä½¿ç”¨FP16ç²¾åº¦æ—¶ï¼Œæ¢¯åº¦å¯èƒ½è¿‡å°ï¼Œéœ€è¦æ”¾å¤§åæ›´æ–°å‚æ•°
    if amp and device.type == 'cuda':
        try:
            # ä½¿ç”¨æ–°çš„API (PyTorch 2.0+)
            grad_scaler = torch.amp.GradScaler('cuda', enabled=True)
        except AttributeError:
            # å‘åå…¼å®¹æ—§ç‰ˆæœ¬PyTorch
            grad_scaler = torch.cuda.amp.GradScaler(enabled=True)
    else:
        # CPUæˆ–MPSè®¾å¤‡ä¸æ”¯æŒæ··åˆç²¾åº¦ï¼Œåˆ›å»ºç¦ç”¨çš„scaler
        grad_scaler = torch.cuda.amp.GradScaler(enabled=False)
    
    # 5.4 æŸå¤±å‡½æ•°é…ç½®
    # æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©åˆé€‚çš„æŸå¤±å‡½æ•°
    # å¤šåˆ†ç±»ä»»åŠ¡ä½¿ç”¨äº¤å‰ç†µæŸå¤±ï¼ŒäºŒåˆ†ç±»ä»»åŠ¡ä½¿ç”¨BCEæŸå¤±
    if model.n_classes > 1:
        criterion = nn.CrossEntropyLoss()  # å¤šåˆ†ç±»äº¤å‰ç†µæŸå¤±
        logging.info('ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼ˆå¤šåˆ†ç±»ä»»åŠ¡ï¼‰')
    else:
        criterion = nn.BCEWithLogitsLoss()  # äºŒåˆ†ç±»BCEæŸå¤±
        logging.info('ä½¿ç”¨BCEæŸå¤±å‡½æ•°ï¼ˆäºŒåˆ†ç±»ä»»åŠ¡ï¼‰')
    
    # 5.5 æ—©åœæœºåˆ¶åˆå§‹åŒ–
    early_stopping = EarlyStopping(
        patience=Config.PATIENCE, 
        min_delta=Config.MIN_DELTA, 
        restore_best_weights=True
    )
    
    # 5.6 è®­ç»ƒçŠ¶æ€å˜é‡
    global_step = 0  # å…¨å±€è®­ç»ƒæ­¥æ•°è®¡æ•°å™¨ï¼Œç”¨äºWandBæ—¥å¿—è®°å½•
    accumulation_steps = 0  # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°è®¡æ•°å™¨
    
    # è®¡ç®—æœ‰æ•ˆæ‰¹æ¬¡å¤§å°
    effective_batch_size = batch_size * accumulate_grad_batches
    logging.info(f'æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: {effective_batch_size} (æ‰¹æ¬¡å¤§å°: {batch_size} Ã— ç´¯ç§¯æ­¥æ•°: {accumulate_grad_batches})')
    
    logging.info('è®­ç»ƒç»„ä»¶åˆå§‹åŒ–å®Œæˆ')

    # ================================
    # 6. ä¸»è®­ç»ƒå¾ªç¯
    # ================================
    # å¼€å§‹é€è½®è®­ç»ƒï¼Œæ¯è½®éå†æ•´ä¸ªè®­ç»ƒé›†ä¸€æ¬¡
    for epoch in range(1, epochs + 1):
        # å°†æ¨¡å‹è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
        # è¿™ä¼šå¯ç”¨dropoutã€batch normalizationçš„è®­ç»ƒæ¨¡å¼ç­‰è®­ç»ƒæ—¶ç‰¹æœ‰çš„è¡Œä¸º
        model.train()
        epoch_loss = 0  # å½“å‰è½®æ¬¡çš„ç´¯ç§¯æŸå¤±
        
        # åˆ›å»ºè¿›åº¦æ¡ï¼Œæ˜¾ç¤ºå½“å‰è½®æ¬¡çš„è®­ç»ƒè¿›åº¦
        with tqdm(total=n_train, desc=f'è½®æ¬¡ {epoch}/{epochs}', unit='å¼ ') as pbar:
            # éå†è®­ç»ƒé›†ä¸­çš„æ‰€æœ‰æ‰¹æ¬¡
            for batch in train_loader:
                # ä»æ‰¹æ¬¡ä¸­æå–å›¾åƒå’ŒçœŸå®æ©ç 
                images, true_masks = batch['image'], batch['mask']

                # éªŒè¯å›¾åƒé€šé“æ•°æ˜¯å¦ä¸æ¨¡å‹æœŸæœ›ä¸€è‡´
                # è¿™æ˜¯é‡è¦çš„å®‰å…¨æ£€æŸ¥ï¼Œé¿å…ç»´åº¦ä¸åŒ¹é…é”™è¯¯
                assert images.shape[1] == model.n_channels, \
                    f'æ¨¡å‹å®šä¹‰ä¸º{model.n_channels}è¾“å…¥é€šé“ï¼Œä½†å›¾ç‰‡å®é™…ä¸º{images.shape[1]}é€šé“ï¼Œè¯·æ£€æŸ¥å›¾ç‰‡åŠ è½½æ˜¯å¦æ­£ç¡®ã€‚'

                # å°†æ•°æ®ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡å¹¶è½¬æ¢ä¸ºåˆé€‚çš„ç±»å‹
                # images: è½¬æ¢ä¸ºfloat32ç±»å‹ï¼Œä½¿ç”¨channels_lastå†…å­˜æ ¼å¼ä¼˜åŒ–GPUæ€§èƒ½
                # true_masks: è½¬æ¢ä¸ºlongç±»å‹ï¼Œå› ä¸ºæ©ç æ ‡ç­¾é€šå¸¸æ˜¯æ•´æ•°ç´¢å¼•
                images = images.to(device=device, dtype=torch.float32, 
                                 memory_format=torch.channels_last if device.type == 'cuda' else torch.contiguous_format,
                                 non_blocking=True)
                true_masks = true_masks.to(device=device, dtype=torch.long, non_blocking=True)

                # ================================
                # 6.1 å‰å‘ä¼ æ’­ä¸æŸå¤±è®¡ç®—
                # ================================
                # ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦è¿›è¡Œå‰å‘ä¼ æ’­ï¼Œæå‡è®­ç»ƒé€Ÿåº¦å¹¶å‡å°‘æ˜¾å­˜å ç”¨
                # å¯¹äºMPSè®¾å¤‡éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œå› ä¸ºApple Siliconå¯¹autocastæ”¯æŒæœ‰é™
                with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):
                    # æ¨¡å‹å‰å‘ä¼ æ’­ï¼Œå¾—åˆ°é¢„æµ‹ç»“æœ
                    # masks_predå½¢çŠ¶ï¼š(batch_size, n_classes, height, width)
                    masks_pred = model(images)
                    
                    # æ ¹æ®ä»»åŠ¡ç±»å‹è®¡ç®—ä¸åŒçš„æŸå¤±å‡½æ•°ç»„åˆ
                    if model.n_classes == 1:
                        # ================================
                        # äºŒåˆ†ç±»ä»»åŠ¡æŸå¤±è®¡ç®—
                        # ================================
                        # ä½¿ç”¨BCEæŸå¤± + DiceæŸå¤±çš„ç»„åˆ
                        # BCEæŸå¤±ï¼šäºŒå…ƒäº¤å‰ç†µï¼Œå¤„ç†å‰æ™¯/èƒŒæ™¯åˆ†å‰²
                        bce_loss = criterion(masks_pred.squeeze(1), true_masks.float())
                        
                        # DiceæŸå¤±ï¼šä¸“é—¨ä¼˜åŒ–åˆ†å‰²é‡å åº¦ï¼Œæ”¹å–„è¾¹ç•Œåˆ†å‰²æ•ˆæœ
                        # ä½¿ç”¨sigmoidæ¿€æ´»å‡½æ•°å°†logitsè½¬æ¢ä¸ºæ¦‚ç‡
                        dice_loss_value = dice_loss(
                            F.sigmoid(masks_pred.squeeze(1)), 
                            true_masks.float(), 
                            multiclass=False
                        )
                        
                        # æ€»æŸå¤± = BCEæŸå¤± + DiceæŸå¤±
                        # è¿™ç§ç»„åˆåœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­è¡¨ç°ä¼˜å¼‚
                        loss = bce_loss + dice_loss_value
                        
                    else:
                        # ================================
                        # å¤šåˆ†ç±»ä»»åŠ¡æŸå¤±è®¡ç®—
                        # ================================
                        # ä½¿ç”¨äº¤å‰ç†µæŸå¤± + DiceæŸå¤±çš„ç»„åˆ
                        # äº¤å‰ç†µæŸå¤±ï¼šå¤„ç†å¤šä¸ªç±»åˆ«çš„å‰æ™¯åˆ†å‰²
                        ce_loss = criterion(masks_pred, true_masks)
                        
                        # å°†é¢„æµ‹ç»“æœè½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒï¼ˆsoftmaxï¼‰
                        pred_probs = F.softmax(masks_pred, dim=1)
                        
                        # å°†çœŸå®æ ‡ç­¾è½¬æ¢ä¸ºone-hotç¼–ç æ ¼å¼ï¼ˆä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼‰
                        true_one_hot = F.one_hot(true_masks, model.n_classes).permute(0, 3, 1, 2).float()
                        
                        # è®¡ç®—å¤šåˆ†ç±»DiceæŸå¤±
                        dice_loss_value = dice_loss(pred_probs, true_one_hot, multiclass=True)
                        
                        # æ€»æŸå¤± = äº¤å‰ç†µæŸå¤± + DiceæŸå¤±
                        loss = ce_loss + dice_loss_value

                # ================================
                # 6.2 åå‘ä¼ æ’­ä¸å‚æ•°ä¼˜åŒ–ï¼ˆæ”¯æŒæ¢¯åº¦ç´¯ç§¯ï¼‰
                # ================================
                # å°†æŸå¤±é™¤ä»¥ç´¯ç§¯æ­¥æ•°ï¼Œå®ç°æ¢¯åº¦ç´¯ç§¯
                loss = loss / accumulate_grad_batches
                
                # æ¢¯åº¦ç¼©æ”¾åå‘ä¼ æ’­
                # åœ¨æ··åˆç²¾åº¦è®­ç»ƒä¸­ï¼ŒæŸå¤±éœ€è¦å…ˆæ”¾å¤§å†åå‘ä¼ æ’­
                # è¿™æ ·å¯ä»¥é¿å…æ¢¯åº¦ä¸‹æº¢é—®é¢˜ï¼Œä¿æŒè®­ç»ƒç¨³å®šæ€§
                grad_scaler.scale(loss).backward()
                
                accumulation_steps += 1
                
                # å½“è¾¾åˆ°ç´¯ç§¯æ­¥æ•°æ—¶ï¼Œæ‰§è¡Œå‚æ•°æ›´æ–°
                if accumulation_steps % accumulate_grad_batches == 0:
                    # å–æ¶ˆæ¢¯åº¦ç¼©æ”¾ï¼Œå‡†å¤‡è¿›è¡Œæ¢¯åº¦è£å‰ªå’Œå‚æ•°æ›´æ–°
                    grad_scaler.unscale_(optimizer)
                    
                    # æ¢¯åº¦è£å‰ªï¼šé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
                    # å½“æ¢¯åº¦çš„L2èŒƒæ•°è¶…è¿‡é˜ˆå€¼æ—¶ï¼ŒæŒ‰æ¯”ä¾‹ç¼©æ”¾æ‰€æœ‰æ¢¯åº¦
                    # è¿™æ˜¯RNNå’Œæ·±åº¦ç½‘ç»œè®­ç»ƒä¸­çš„é‡è¦æŠ€æœ¯
                    torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)
                    
                    # æ‰§è¡Œä¼˜åŒ–å™¨æ­¥éª¤ï¼Œæ›´æ–°æ¨¡å‹å‚æ•°
                    # åœ¨æ··åˆç²¾åº¦è®­ç»ƒä¸­ï¼Œéœ€è¦å…ˆç¼©æ”¾æ¢¯åº¦å†æ›´æ–°
                    grad_scaler.step(optimizer)
                    
                    # æ›´æ–°æ¢¯åº¦ç¼©æ”¾å™¨çš„å†…éƒ¨çŠ¶æ€
                    # æ ¹æ®æ˜¯å¦å‘ç”Ÿæ¢¯åº¦æº¢å‡ºï¼ŒåŠ¨æ€è°ƒæ•´ç¼©æ”¾å› å­
                    grad_scaler.update()
                    
                    # æ¸…ç©ºæ¢¯åº¦ç¼“å­˜ï¼Œset_to_none=Trueå¯ä»¥èŠ‚çœå†…å­˜
                    optimizer.zero_grad(set_to_none=True)

                # ================================
                # 6.3 è®­ç»ƒçŠ¶æ€æ›´æ–°å’Œæ—¥å¿—è®°å½•
                # ================================
                # æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤º
                pbar.update(images.shape[0])
                global_step += 1
                epoch_loss += loss.item()  # ç´¯åŠ å½“å‰è½®æ¬¡çš„æŸå¤±
                
                # è®°å½•è®­ç»ƒæŒ‡æ ‡åˆ°WandBï¼ˆæ¯éš”ä¸€å®šæ­¥æ•°è®°å½•ä¸€æ¬¡ï¼Œå‡å°‘I/Oå¼€é”€ï¼‰
                if global_step % max(1, len(train_loader) // 20) == 0:  # æ¯è½®è®°å½•20æ¬¡
                    experiment.log({
                        'è®­ç»ƒæŸå¤±': loss.item() * accumulate_grad_batches,  # æ¢å¤åŸå§‹æŸå¤±å€¼
                        'æ­¥æ•°': global_step,            # å…¨å±€è®­ç»ƒæ­¥æ•°
                        'è½®æ¬¡': epoch,                 # å½“å‰è½®æ¬¡
                        'å­¦ä¹ ç‡': optimizer.param_groups[0]['lr'],  # å½“å‰å­¦ä¹ ç‡
                        'æœ‰æ•ˆæ‰¹æ¬¡å¤§å°': effective_batch_size  # æœ‰æ•ˆæ‰¹æ¬¡å¤§å°
                    })
                
                # æ›´æ–°è¿›åº¦æ¡åç¼€ï¼Œæ˜¾ç¤ºå½“å‰æ‰¹æ¬¡çš„æŸå¤±
                pbar.set_postfix(**{'æŸå¤± (æ‰¹æ¬¡)': loss.item()})

                # ================================
                # 6.4 å®šæœŸéªŒè¯å’Œå¯è§†åŒ–è®°å½•
                # ================================
                # è®¡ç®—éªŒè¯é—´éš”æ­¥æ•°ï¼Œæ¯è½®è®­ç»ƒè¿›è¡Œ5æ¬¡éªŒè¯
                # è¿™æ ·å¯ä»¥æ›´é¢‘ç¹åœ°ç›‘æ§æ¨¡å‹æ€§èƒ½ï¼ŒåŠæ—¶å‘ç°è¿‡æ‹Ÿåˆç­‰é—®é¢˜
                division_step = (n_train // (5 * batch_size))
                if division_step > 0:
                    if global_step % division_step == 0:
                        # æ”¶é›†æ¨¡å‹æƒé‡å’Œæ¢¯åº¦çš„åˆ†å¸ƒä¿¡æ¯
                        histograms = _log_histograms(model)

                        # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½
                        val_score = evaluate(model, val_loader, device, amp)
                        
                        # æ ¹æ®éªŒè¯åˆ†æ•°æ›´æ–°å­¦ä¹ ç‡è°ƒåº¦å™¨
                        scheduler.step(val_score)

                        # è®°å½•éªŒè¯ç»“æœ
                        logging.info(f'éªŒè¯é›†Diceåˆ†æ•°: {val_score:.4f}')
                        
                        # è®°å½•è¯¦ç»†çš„éªŒè¯ä¿¡æ¯åˆ°WandB
                        try:
                            pred_mask, true_mask = _prepare_mask_for_logging(masks_pred, true_masks, model)
                            
                            experiment.log({
                                'å­¦ä¹ ç‡': optimizer.param_groups[0]['lr'],  # å½“å‰å­¦ä¹ ç‡
                                'éªŒè¯Diceåˆ†æ•°': val_score,                       # éªŒè¯é›†Diceåˆ†æ•°
                                'å›¾åƒ': wandb.Image(images[0].cpu()),            # è¾“å…¥å›¾åƒ
                                'æ©ç ': {                                         # æ©ç å¯¹æ¯”
                                    'çœŸå®': wandb.Image(true_mask),                # çœŸå®æ©ç 
                                    'é¢„æµ‹': wandb.Image(pred_mask),                # é¢„æµ‹æ©ç 
                                },
                                'æ­¥æ•°': global_step,                               # å…¨å±€æ­¥æ•°
                                'è½®æ¬¡': epoch,                                    # å½“å‰è½®æ¬¡
                                **histograms                                       # æƒé‡å’Œæ¢¯åº¦åˆ†å¸ƒ
                            })
                        except Exception as e:
                            # å¦‚æœè®°å½•å¤±è´¥ï¼Œç»§ç»­è®­ç»ƒè€Œä¸ä¸­æ–­
                            logging.warning(f'WandBè®°å½•å¤±è´¥: {e}')
                            pass

        # ================================
        # 6.5 æ¯è½®ç»“æŸåçš„éªŒè¯å’Œæ—©åœæ£€æŸ¥
        # ================================
        # åœ¨æ¯ä¸ªepochç»“æŸåè¿›è¡Œå®Œæ•´éªŒè¯
        model.eval()
        with torch.no_grad():
            epoch_val_score = evaluate(model, val_loader, device, amp)
            logging.info(f'Epoch {epoch} éªŒè¯é›†Diceåˆ†æ•°: {epoch_val_score:.4f}')
            
            # æ£€æŸ¥æ—©åœæ¡ä»¶
            if early_stopping(epoch_val_score, model):
                logging.info(f'æ—©åœè§¦å‘ï¼è¿ç»­{Config.PATIENCE}è½®éªŒè¯æŒ‡æ ‡æœªæå‡')
                logging.info(f'æœ€ä½³éªŒè¯åˆ†æ•°: {early_stopping.best_score:.4f}')
                break
        
        # ================================
        # 6.6 æ¨¡å‹æ£€æŸ¥ç‚¹ä¿å­˜
        # ================================
        # æ¯è½®è®­ç»ƒç»“æŸåä¿å­˜æ¨¡å‹çŠ¶æ€ï¼Œæ”¯æŒæ–­ç‚¹ç»­è®­å’Œæ¨¡å‹æ¢å¤
        if save_checkpoint:
            # ç¡®ä¿æ£€æŸ¥ç‚¹ç›®å½•å­˜åœ¨
            Path(Config.CHECKPOINT_DIR).mkdir(parents=True, exist_ok=True)
            
            avg_train_loss = epoch_loss / len(train_loader)
            
            # æ„å»ºæ£€æŸ¥ç‚¹æ•°æ®å­—å…¸
            checkpoint = {
                'epoch': epoch,                                    # å½“å‰è®­ç»ƒè½®æ¬¡
                'model_state_dict': model.state_dict(),           # æ¨¡å‹å‚æ•°çŠ¶æ€
                'optimizer_state_dict': optimizer.state_dict(),   # ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆåŒ…æ‹¬åŠ¨é‡ç­‰ï¼‰
                'scheduler_state_dict': scheduler.state_dict(),   # å­¦ä¹ ç‡è°ƒåº¦å™¨çŠ¶æ€
                'loss': avg_train_loss,                           # å¹³å‡æŸå¤±
                'val_score': epoch_val_score,                     # éªŒè¯åˆ†æ•°
                'mask_values': dataset.mask_values                # æ•°æ®é›†æ©ç å€¼ï¼ˆç”¨äºæ¨ç†æ—¶çš„æ ‡ç­¾æ˜ å°„ï¼‰
            }
            
            # ä¿å­˜å½“å‰epochæ£€æŸ¥ç‚¹
            checkpoint_path = Config.CHECKPOINT_DIR / f'checkpoint_epoch{epoch}.pth'
            torch.save(checkpoint, str(checkpoint_path))
            logging.info(f'æ£€æŸ¥ç‚¹ {epoch} å·²ä¿å­˜è‡³ {checkpoint_path}!')
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            best_model_path = Config.CHECKPOINT_DIR / 'best_model.pth'
            is_best_model = (epoch_val_score >= early_stopping.best_score - Config.MIN_DELTA)
            if is_best_model:
                torch.save(checkpoint, str(best_model_path))
                logging.info(f'æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜ï¼éªŒè¯åˆ†æ•°: {epoch_val_score:.4f}')
            
            # è®°å½•æ£€æŸ¥ç‚¹ä¿¡æ¯åˆ°WandB
            experiment.log({
                'è½®æ¬¡': epoch,
                'å¹³å‡è®­ç»ƒæŸå¤±': avg_train_loss,
                'éªŒè¯åˆ†æ•°': epoch_val_score,
                'æ£€æŸ¥ç‚¹å·²ä¿å­˜': True,
                'æ˜¯å¦æœ€ä½³æ¨¡å‹': is_best_model
            })



def get_args():
    """
    å‘½ä»¤è¡Œå‚æ•°è§£æå‡½æ•°ï¼Œå¤„ç†è®­ç»ƒè„šæœ¬çš„å‘½ä»¤è¡Œè¾“å…¥å‚æ•°
    
    è¯¥å‡½æ•°ä½¿ç”¨argparseæ¨¡å—è§£æå‘½ä»¤è¡Œå‚æ•°ï¼Œæä¾›äº†çµæ´»çš„è®­ç»ƒé…ç½®é€‰é¡¹ã€‚
    æ‰€æœ‰å‚æ•°éƒ½æœ‰åˆç†çš„é»˜è®¤å€¼ï¼Œæ”¯æŒå¿«é€Ÿå¼€å§‹è®­ç»ƒæˆ–ç²¾ç»†è°ƒä¼˜ã€‚
    
    ================================
    æ”¯æŒçš„å‚æ•°è¯¦è§£ï¼š
    ================================
    
    åŸºç¡€è®­ç»ƒå‚æ•°ï¼š
    --epochs, -e (int): è®­ç»ƒè½®æ•°
        - é»˜è®¤å€¼: 5
        - å»ºè®®å€¼: å°æ•°æ®é›†50-100è½®ï¼Œå¤§æ•°æ®é›†20-50è½®
        - å½±å“: è¿‡å°‘å¯èƒ½å¯¼è‡´æ¬ æ‹Ÿåˆï¼Œè¿‡å¤šå¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆ
    
    --batch-size, -b (int): æ‰¹æ¬¡å¤§å°
        - é»˜è®¤å€¼: 1
        - å»ºè®®å€¼: æ ¹æ®æ˜¾å­˜è°ƒæ•´ï¼Œ8GBæ˜¾å­˜å¯ç”¨4-8ï¼Œ16GBå¯ç”¨8-16
        - å½±å“: å½±å“è®­ç»ƒç¨³å®šæ€§å’Œæ˜¾å­˜å ç”¨
    
    --learning-rate, -l (float): å­¦ä¹ ç‡
        - é»˜è®¤å€¼: 1e-5
        - å»ºè®®èŒƒå›´: 1e-4 åˆ° 1e-6
        - å½±å“: æ§åˆ¶æ¨¡å‹å‚æ•°æ›´æ–°çš„æ­¥é•¿
    
    æ•°æ®å’Œæ¨¡å‹å‚æ•°ï¼š
    --load, -f (str): é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
        - é»˜è®¤å€¼: Falseï¼ˆä¸ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼‰
        - ç”¨é€”: ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒæˆ–ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
        - æ ¼å¼: .pthæ–‡ä»¶è·¯å¾„
    
    --scale, -s (float): å›¾åƒç¼©æ”¾æ¯”ä¾‹
        - é»˜è®¤å€¼: 0.5
        - èŒƒå›´: (0, 1]
        - å½±å“: æ§åˆ¶è¾“å…¥å›¾åƒå°ºå¯¸ï¼Œå¹³è¡¡æ˜¾å­˜å ç”¨å’Œåˆ†å‰²ç²¾åº¦
    
    --validation, -v (float): éªŒè¯é›†æ¯”ä¾‹
        - é»˜è®¤å€¼: 10.0ï¼ˆè¡¨ç¤º10%ï¼‰
        - èŒƒå›´: 0-100
        - å»ºè®®å€¼: å°æ•°æ®é›†20-30%ï¼Œå¤§æ•°æ®é›†10-20%
    
    --classes, -c (int): åˆ†å‰²ç±»åˆ«æ•°
        - é»˜è®¤å€¼: 2
        - å«ä¹‰: åŒ…æ‹¬èƒŒæ™¯ç±»åœ¨å†…çš„æ€»ç±»åˆ«æ•°
        - å½±å“: å†³å®šæ¨¡å‹è¾“å‡ºé€šé“æ•°å’ŒæŸå¤±å‡½æ•°é€‰æ‹©
    
    ä¼˜åŒ–å’Œæ€§èƒ½å‚æ•°ï¼š
    --amp (flag): å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
        - é»˜è®¤å€¼: False
        - æ•ˆæœ: å‡å°‘50%æ˜¾å­˜å ç”¨ï¼Œæå‡è®­ç»ƒé€Ÿåº¦
        - é€‚ç”¨: æ˜¾å­˜ä¸è¶³æˆ–éœ€è¦åŠ é€Ÿè®­ç»ƒæ—¶
    
    --bilinear (flag): ä½¿ç”¨åŒçº¿æ€§æ’å€¼ä¸Šé‡‡æ ·
        - é»˜è®¤å€¼: Falseï¼ˆä½¿ç”¨è½¬ç½®å·ç§¯ï¼‰
        - æ•ˆæœ: å‡å°‘å‚æ•°é‡ï¼Œä½†å¯èƒ½å½±å“åˆ†å‰²ç²¾åº¦
        - é€‚ç”¨: æ¨¡å‹å‹ç¼©æˆ–æ˜¾å­˜æåº¦ä¸è¶³æ—¶
    
    ================================
    ä½¿ç”¨ç¤ºä¾‹ï¼š
    ================================
    
    # åŸºç¡€è®­ç»ƒ
    python train.py --epochs 50 --batch-size 8 --learning-rate 1e-4
    
    # é«˜æ€§èƒ½è®­ç»ƒï¼ˆæ··åˆç²¾åº¦+å¤§æ‰¹æ¬¡ï¼‰
    python train.py --epochs 100 --batch-size 16 --amp --scale 0.75
    
    # ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
    python train.py --load checkpoints/checkpoint_epoch10.pth --epochs 50
    
    # å¤šåˆ†ç±»åˆ†å‰²ä»»åŠ¡
    python train.py --classes 5 --epochs 80 --batch-size 4
    
    # æ˜¾å­˜ä¼˜åŒ–è®­ç»ƒ
    python train.py --amp --bilinear --batch-size 2 --scale 0.25
    
    ================================
    è¿”å›å€¼å’Œå¼‚å¸¸ï¼š
    ================================
    
    Returns:
        argparse.Namespace: è§£æåçš„å‚æ•°å¯¹è±¡ï¼ŒåŒ…å«æ‰€æœ‰è®­ç»ƒé…ç½®
        
    Raises:
        SystemExit: å½“å‚æ•°è§£æå¤±è´¥æˆ–ç”¨æˆ·è¯·æ±‚å¸®åŠ©æ—¶é€€å‡ºç¨‹åº
        
    ================================
    æ³¨æ„äº‹é¡¹ï¼š
    ================================
    
    1. å‚æ•°éªŒè¯ï¼š
       - æ‰€æœ‰æ•°å€¼å‚æ•°éƒ½æœ‰èŒƒå›´æ£€æŸ¥
       - æ–‡ä»¶è·¯å¾„ä¼šè‡ªåŠ¨éªŒè¯å­˜åœ¨æ€§
       - ä¸åˆç†çš„å‚æ•°ç»„åˆä¼šç»™å‡ºè­¦å‘Š
    
    2. é»˜è®¤å€¼è®¾è®¡ï¼š
       - æ‰€æœ‰å‚æ•°éƒ½æœ‰ç»è¿‡æµ‹è¯•çš„é»˜è®¤å€¼
       - é»˜è®¤é…ç½®é€‚åˆå¤§å¤šæ•°åœºæ™¯
       - å¯ä»¥æ ¹æ®å…·ä½“éœ€æ±‚è°ƒæ•´
    
    3. å…¼å®¹æ€§ï¼š
       - æ”¯æŒçŸ­å‚æ•°åå’Œé•¿å‚æ•°å
       - å¸ƒå°”æ ‡å¿—ä¸éœ€è¦æŒ‡å®šå€¼
       - æ•°å€¼å‚æ•°æ”¯æŒç§‘å­¦è®¡æ•°æ³•
    
    4. é”™è¯¯å¤„ç†ï¼š
       - æ— æ•ˆå‚æ•°ä¼šç»™å‡ºæ¸…æ™°çš„é”™è¯¯ä¿¡æ¯
       - æä¾›ä½¿ç”¨å¸®åŠ©å’Œç¤ºä¾‹
       - è‡ªåŠ¨æ£€æµ‹å¸¸è§é…ç½®é”™è¯¯
    """
    parser = argparse.ArgumentParser(description='è®­ç»ƒUNetç”¨äºå›¾åƒä¸æ©ç åˆ†å‰²')
    parser.add_argument('--epochs', '-e', metavar='E', type=int, default=5, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch-size', '-b', dest='batch_size', metavar='B', type=int, default=1, help='æ¯æ‰¹æ¬¡æ ·æœ¬æ•°')
    parser.add_argument('--learning-rate', '-l', metavar='LR', type=float, default=1e-5,
                        help='å­¦ä¹ ç‡', dest='lr')
    parser.add_argument('--load', '-f', type=str, default=False, help='ä».pthæ–‡ä»¶åŠ è½½æ¨¡å‹')
    parser.add_argument('--scale', '-s', type=float, default=0.5, help='å›¾ç‰‡ç¼©æ”¾å› å­')
    parser.add_argument('--validation', '-v', dest='val', type=float, default=10.0,
                        help='éªŒè¯é›†æ¯”ä¾‹(0-100)')
    parser.add_argument('--amp', action='store_true', default=False, help='ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ')
    parser.add_argument('--bilinear', action='store_true', default=False, help='ä½¿ç”¨åŒçº¿æ€§ä¸Šé‡‡æ ·')
    parser.add_argument('--classes', '-c', type=int, default=2, help='ç±»åˆ«æ•°')
    parser.add_argument('--accumulate-grad-batches', type=int, default=1, 
                        help='æ¢¯åº¦ç´¯ç§¯æ‰¹æ¬¡æ•°ï¼Œç”¨äºæ¨¡æ‹Ÿæ›´å¤§çš„æ‰¹æ¬¡å¤§å°')

    return parser.parse_args()



# ================================
# ä¸»ç¨‹åºå…¥å£
# ================================
if __name__ == '__main__':
    """
    ä¸»ç¨‹åºå…¥å£ç‚¹ï¼Œè´Ÿè´£åˆå§‹åŒ–è®­ç»ƒç¯å¢ƒå¹¶å¯åŠ¨è®­ç»ƒè¿‡ç¨‹
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. è§£æå‘½ä»¤è¡Œå‚æ•°
    2. åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    3. æ£€æµ‹å’Œé…ç½®è®¡ç®—è®¾å¤‡
    4. åˆ›å»ºå’Œé…ç½®UNetæ¨¡å‹
    5. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¯é€‰ï¼‰
    6. å¯åŠ¨è®­ç»ƒæµç¨‹
    7. å¤„ç†å¼‚å¸¸å’Œé”™è¯¯æ¢å¤
    
    å¼‚å¸¸å¤„ç†ï¼š
    - æ˜¾å­˜æº¢å‡ºï¼šè‡ªåŠ¨å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹æœºåˆ¶
    - æ¨¡å‹åŠ è½½å¤±è´¥ï¼šæä¾›æ¸…æ™°çš„é”™è¯¯ä¿¡æ¯
    - è®¾å¤‡é…ç½®é—®é¢˜ï¼šè‡ªåŠ¨å›é€€åˆ°CPU
    """
    
    # ================================
    # 1. ç¯å¢ƒåˆå§‹åŒ–
    # ================================
    # è§£æå‘½ä»¤è¡Œå‚æ•°ï¼Œè·å–è®­ç»ƒé…ç½®
    args = get_args()
    
    # é…ç½®æ—¥å¿—ç³»ç»Ÿ
    # ä½¿ç”¨INFOçº§åˆ«è®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„é‡è¦ä¿¡æ¯
    logging.basicConfig(
        level=logging.INFO, 
        format='%(asctime)s - %(levelname)s: %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # è‡ªåŠ¨æ£€æµ‹å’Œé…ç½®è®¡ç®—è®¾å¤‡
    # ä¼˜å…ˆä½¿ç”¨GPUï¼Œå¦‚æœä¸å¯ç”¨åˆ™å›é€€åˆ°CPU
    if torch.cuda.is_available():
        device = torch.device('cuda')
        logging.info(f'æ£€æµ‹åˆ°CUDAè®¾å¤‡ï¼Œä½¿ç”¨GPUè®­ç»ƒ: {torch.cuda.get_device_name()}')
        logging.info(f'GPUæ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB')
    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        device = torch.device('mps')
        logging.info('æ£€æµ‹åˆ°Apple Siliconè®¾å¤‡ï¼Œä½¿ç”¨MPSè®­ç»ƒ')
    else:
        device = torch.device('cpu')
        logging.warning('æœªæ£€æµ‹åˆ°GPUï¼Œä½¿ç”¨CPUè®­ç»ƒï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰')
    
    logging.info(f'è®­ç»ƒè®¾å¤‡: {device}')

    # ================================
    # 2. æ¨¡å‹åˆ›å»ºå’Œé…ç½®
    # ================================
    # åˆ›å»ºUNetæ¨¡å‹å®ä¾‹
    # n_channels=3: RGBå›¾åƒè¾“å…¥é€šé“æ•°
    # n_classes: åˆ†å‰²ç±»åˆ«æ•°ï¼ˆåŒ…æ‹¬èƒŒæ™¯ç±»ï¼‰
    # bilinear: æ˜¯å¦ä½¿ç”¨åŒçº¿æ€§æ’å€¼ä¸Šé‡‡æ ·
    model = UNet(
        n_channels=3, 
        n_classes=args.classes, 
        bilinear=args.bilinear
    )
    
    # é…ç½®å†…å­˜æ ¼å¼ä¼˜åŒ–
    # channels_lastæ ¼å¼å¯ä»¥æå‡GPUæ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å·ç§¯æ“ä½œä¸­
    model = model.to(memory_format=torch.channels_last)

    # æ‰“å°æ¨¡å‹ç»“æ„ä¿¡æ¯
    logging.info(f'''
    ================================
    æ¨¡å‹é…ç½®ä¿¡æ¯
    ================================
    è¾“å…¥é€šé“æ•°:         {model.n_channels} (RGBå›¾åƒ)
    è¾“å‡ºé€šé“æ•°:         {model.n_classes} (åˆ†å‰²ç±»åˆ«)
    ä¸Šé‡‡æ ·æ–¹å¼:         {"åŒçº¿æ€§æ’å€¼" if model.bilinear else "è½¬ç½®å·ç§¯"}
    æ¨¡å‹å‚æ•°é‡:         {sum(p.numel() for p in model.parameters()):,}
    å¯è®­ç»ƒå‚æ•°:         {sum(p.numel() for p in model.parameters() if p.requires_grad):,}
    ================================
    ''')

    # ================================
    # 3. é¢„è®­ç»ƒæ¨¡å‹åŠ è½½
    # ================================
    # å¦‚æœæŒ‡å®šäº†é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼Œåˆ™åŠ è½½æ¨¡å‹æƒé‡
    if args.load:
        try:
            logging.info(f'æ­£åœ¨ä» {args.load} åŠ è½½é¢„è®­ç»ƒæ¨¡å‹...')
            
            # åŠ è½½æ£€æŸ¥ç‚¹æ–‡ä»¶
            state_dict = torch.load(args.load, map_location=device)
            
            # æ¸…ç†æ•°æ®é›†ç›¸å…³çš„å‚æ•°
            # mask_valuesæ˜¯æ•°æ®é›†ç‰¹å®šçš„ï¼Œä¸å±äºæ¨¡å‹å‚æ•°
            if 'mask_values' in state_dict:
                del state_dict['mask_values']
                logging.info('å·²ç§»é™¤æ•°æ®é›†ç›¸å…³çš„mask_valueså‚æ•°')
            
            # åŠ è½½æ¨¡å‹å‚æ•°
            model.load_state_dict(state_dict, strict=False)
            logging.info('âœ… é¢„è®­ç»ƒæ¨¡å‹åŠ è½½æˆåŠŸï¼')
            
            # æ˜¾ç¤ºåŠ è½½çš„æ£€æŸ¥ç‚¹ä¿¡æ¯
            if 'epoch' in state_dict:
                logging.info(f'æ£€æŸ¥ç‚¹è½®æ¬¡: {state_dict["epoch"]}')
            if 'loss' in state_dict:
                logging.info(f'æ£€æŸ¥ç‚¹æŸå¤±: {state_dict["loss"]:.4f}')
                
        except FileNotFoundError:
            logging.error(f'âŒ æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {args.load}')
            logging.info('è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®')
            sys.exit(1)
        except Exception as e:
            logging.error(f'âŒ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹æ—¶å‡ºé”™: {str(e)}')
            logging.info('è¯·æ£€æŸ¥æ£€æŸ¥ç‚¹æ–‡ä»¶æ˜¯å¦å®Œæ•´æˆ–å…¼å®¹')
            sys.exit(1)

    # å°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ï¼ˆGPU/CPUï¼‰
    model.to(device=device)
    logging.info(f'æ¨¡å‹å·²ç§»åŠ¨åˆ°è®¾å¤‡: {device}')

    # ================================
    # 4. è®­ç»ƒæµç¨‹å¯åŠ¨
    # ================================
    try:
        logging.info('ğŸš€ å¼€å§‹è®­ç»ƒè¿‡ç¨‹...')
        
        # è°ƒç”¨ä¸»è®­ç»ƒå‡½æ•°
        train_model(
            model=model,
            epochs=args.epochs,
            batch_size=args.batch_size,
            learning_rate=args.lr,
            device=device,
            img_scale=args.scale,
            val_percent=args.val / 100,
            amp=args.amp,
            accumulate_grad_batches=args.accumulate_grad_batches
        )
        
        logging.info('ğŸ‰ è®­ç»ƒæˆåŠŸå®Œæˆï¼')
        
    except torch.cuda.OutOfMemoryError as e:
        # ================================
        # 5. æ˜¾å­˜æº¢å‡ºå¼‚å¸¸å¤„ç†
        # ================================
        logging.error('âš ï¸ æ£€æµ‹åˆ°GPUæ˜¾å­˜æº¢å‡ºï¼æ­£åœ¨é‡‡å–è¡¥æ•‘æªæ–½...')
        
        # æ¸…ç†CUDAç¼“å­˜ï¼Œé‡Šæ”¾æœªä½¿ç”¨çš„æ˜¾å­˜
        logging.info('1. æ¸…ç†CUDAç¼“å­˜...')
        torch.cuda.empty_cache()
        
        # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹æœºåˆ¶
        # è¿™ä¼šç”¨è®¡ç®—æ—¶é—´æ¢å–æ˜¾å­˜ç©ºé—´ï¼Œé€‚ç”¨äºå¤§æ¨¡å‹è®­ç»ƒ
        logging.info('2. å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹æœºåˆ¶(gradient checkpointing)...')
        model.use_checkpointing()
        
        # æä¾›ä¼˜åŒ–å»ºè®®
        logging.warning('''
        ================================
        æ˜¾å­˜ä¼˜åŒ–å»ºè®®
        ================================
        å½“å‰é…ç½®å¯èƒ½è¶…å‡ºGPUæ˜¾å­˜é™åˆ¶ï¼Œå»ºè®®ï¼š
        
        1. å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼š
           python train.py --amp
        
        2. å‡å°æ‰¹æ¬¡å¤§å°ï¼š
           python train.py --batch-size 1
        
        3. å‡å°è¾“å…¥å›¾åƒå°ºå¯¸ï¼š
           python train.py --scale 0.25
        
        4. ä½¿ç”¨åŒçº¿æ€§ä¸Šé‡‡æ ·ï¼š
           python train.py --bilinear
        
        5. ç»„åˆä¼˜åŒ–ï¼š
           python train.py --amp --batch-size 1 --scale 0.25 --bilinear
        ================================
        ''')
        
        # é‡æ–°å°è¯•è®­ç»ƒ
        logging.info('3. ä½¿ç”¨ä¼˜åŒ–åçš„è®¾ç½®é‡æ–°è®­ç»ƒ...')
        train_model(
            model=model,
            epochs=args.epochs,
            batch_size=max(1, args.batch_size // 2),  # å‡å°æ‰¹æ¬¡å¤§å°
            learning_rate=args.lr,
            device=device,
            img_scale=min(0.25, args.scale),  # å‡å°å›¾åƒå°ºå¯¸
            val_percent=args.val / 100,
            amp=True,  # å¼ºåˆ¶å¯ç”¨æ··åˆç²¾åº¦
            accumulate_grad_batches=max(2, args.accumulate_grad_batches)  # å¢åŠ æ¢¯åº¦ç´¯ç§¯
        )
        
    except KeyboardInterrupt:
        logging.info('â¹ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­')
        logging.info('ğŸ’¡ æç¤ºï¼šå¯ä»¥ä»æœ€æ–°ä¿å­˜çš„æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ')
        
    except Exception as e:
        logging.error(f'âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {str(e)}')
        logging.error('è¯·æ£€æŸ¥æ•°æ®è·¯å¾„ã€æ¨¡å‹é…ç½®å’Œç³»ç»Ÿç¯å¢ƒ')
        raise e
    
    finally:
        # æ¸…ç†èµ„æº
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        logging.info('ğŸ”§ èµ„æºæ¸…ç†å®Œæˆ')
