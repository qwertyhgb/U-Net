
"""
UNet å›¾åƒåˆ†å‰²æ¨¡å‹è®­ç»ƒè„šæœ¬

è¯¥è„šæœ¬å®ç°äº†å®Œæ•´çš„UNetæ¨¡å‹è®­ç»ƒæµç¨‹ï¼Œä¸“é—¨ç”¨äºåŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ã€‚
UNetæ˜¯ä¸€ç§ç¼–ç å™¨-è§£ç å™¨æ¶æ„çš„å·ç§¯ç¥ç»ç½‘ç»œï¼Œåœ¨å›¾åƒåˆ†å‰²é¢†åŸŸè¡¨ç°ä¼˜å¼‚ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. æ•°æ®é›†åŠ è½½å’Œé¢„å¤„ç†ï¼ˆæ”¯æŒå¤šç§å›¾åƒæ ¼å¼ï¼‰
2. è®­ç»ƒ/éªŒè¯é›†è‡ªåŠ¨åˆ’åˆ†
3. UNetæ¨¡å‹è®­ç»ƒï¼ˆæ”¯æŒäºŒåˆ†ç±»å’Œå¤šåˆ†ç±»ï¼‰
4. æ··åˆç²¾åº¦è®­ç»ƒï¼ˆAMPï¼‰åŠ é€Ÿå’Œæ˜¾å­˜ä¼˜åŒ–
5. å®æ—¶æ€§èƒ½ç›‘æ§å’Œå¯è§†åŒ–ï¼ˆWandBé›†æˆï¼‰
6. è‡ªåŠ¨ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹å’Œæ¨¡å‹æ¢å¤
7. æ¢¯åº¦è£å‰ªå’Œå­¦ä¹ ç‡è°ƒåº¦
8. å¼‚å¸¸å¤„ç†å’Œé”™è¯¯æ¢å¤æœºåˆ¶

è®­ç»ƒç®—æ³•ç‰¹ç‚¹ï¼š
- æŸå¤±å‡½æ•°ï¼šäº¤å‰ç†µ + DiceæŸå¤±ï¼ˆå¤šåˆ†ç±»ï¼‰/ BCE + DiceæŸå¤±ï¼ˆäºŒåˆ†ç±»ï¼‰
- ä¼˜åŒ–å™¨ï¼šAdamWï¼ˆå¸¦æƒé‡è¡°å‡å’ŒAMSGradï¼‰
- å­¦ä¹ ç‡è°ƒåº¦ï¼šä½™å¼¦é€€ç«é‡å¯ï¼ˆCosineAnnealingWarmRestartsï¼‰
- æ•°æ®å¢å¼ºï¼šå›¾åƒç¼©æ”¾ã€éšæœºè£å‰ªç­‰
- æ­£åˆ™åŒ–ï¼šL2æƒé‡è¡°å‡ã€æ¢¯åº¦è£å‰ª

æŠ€æœ¯äº®ç‚¹ï¼š
1. è‡ªåŠ¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆAMPï¼‰å‡å°‘æ˜¾å­˜å ç”¨50%
2. é€šé“ä¼˜å…ˆå†…å­˜æ ¼å¼ä¼˜åŒ–GPUæ€§èƒ½
3. æ¢¯åº¦æ£€æŸ¥ç‚¹æœºåˆ¶å¤„ç†å¤§æ¨¡å‹æ˜¾å­˜ä¸è¶³
4. å®æ—¶è®­ç»ƒç›‘æ§å’Œå¯è§†åŒ–
5. æ™ºèƒ½å¼‚å¸¸å¤„ç†å’Œè‡ªåŠ¨æ¢å¤

é€‚ç”¨åœºæ™¯ï¼š
- åŒ»å­¦å›¾åƒåˆ†å‰²ï¼ˆå™¨å®˜ã€ç—…å˜åŒºåŸŸç­‰ï¼‰
- å«æ˜Ÿå›¾åƒåˆ†å‰²ï¼ˆå»ºç­‘ã€é“è·¯ç­‰ï¼‰
- ç”Ÿç‰©å›¾åƒåˆ†æï¼ˆç»†èƒåˆ†å‰²ç­‰ï¼‰
- è‡ªåŠ¨é©¾é©¶åœºæ™¯åˆ†å‰²

ä½¿ç”¨ç¤ºä¾‹ï¼š
    # åŸºç¡€è®­ç»ƒ
    python train.py --epochs 50 --batch-size 8 --learning-rate 1e-4
    
    # é«˜æ€§èƒ½è®­ç»ƒï¼ˆæ··åˆç²¾åº¦+å¤§æ‰¹æ¬¡ï¼‰
    python train.py --epochs 100 --batch-size 16 --amp --scale 0.75
    
    # ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
    python train.py --load checkpoints/checkpoint_epoch10.pth --epochs 50
"""

# ================================
# æ ‡å‡†åº“å¯¼å…¥
# ================================
import argparse  # ç”¨äºè§£æå‘½ä»¤è¡Œå‚æ•°ï¼Œæ”¯æŒå¤æ‚çš„å‚æ•°é…ç½®
import logging  # ç”¨äºè®°å½•è®­ç»ƒæ—¥å¿—ï¼Œæ”¯æŒä¸åŒçº§åˆ«çš„æ—¥å¿—è¾“å‡º
import os  # å¤„ç†æ“ä½œç³»ç»Ÿç›¸å…³æ“ä½œï¼Œå¦‚æ–‡ä»¶è·¯å¾„ã€ç¯å¢ƒå˜é‡ç­‰
import sys  # ç³»ç»Ÿç›¸å…³åŠŸèƒ½ï¼Œå¦‚ç¨‹åºé€€å‡ºã€å¼‚å¸¸å¤„ç†ç­‰
# ================================
# å·¥å…·åº“å¯¼å…¥
# ================================
from pathlib import Path  # è·¯å¾„å¤„ç†å·¥å…·ï¼Œæä¾›è·¨å¹³å°è·¯å¾„æ“ä½œ
from typing import Tuple, Dict, Any

# ================================
# æ·±åº¦å­¦ä¹ ç›¸å…³åº“å¯¼å…¥
# ================================
import torch  # PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶æ ¸å¿ƒåº“
import torch.nn as nn  # ç¥ç»ç½‘ç»œæ¨¡å—ï¼ŒåŒ…å«å„ç§å±‚å’Œæ¿€æ´»å‡½æ•°
import torch.nn.functional as F  # ç¥ç»ç½‘ç»œå‡½æ•°åº“ï¼Œæä¾›æ— çŠ¶æ€çš„å‡½æ•°å¼æ¥å£
from torch import optim  # ä¼˜åŒ–å™¨æ¨¡å—ï¼ŒåŒ…å«å„ç§æ¢¯åº¦ä¸‹é™ç®—æ³•
from torch.utils.data import DataLoader, random_split  # æ•°æ®åŠ è½½å’Œåˆ’åˆ†å·¥å…·
from tqdm import tqdm  # è¿›åº¦æ¡æ˜¾ç¤ºåº“ï¼Œæä¾›ç¾è§‚çš„è®­ç»ƒè¿›åº¦å¯è§†åŒ–

# ================================
# é¡¹ç›®ç›¸å…³å¯¼å…¥
# ================================
import wandb  # Weights & Biaseså®éªŒç®¡ç†å¹³å°ï¼Œç”¨äºè®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–å’Œè¶…å‚æ•°è°ƒä¼˜
from evaluate import evaluate  # æ¨¡å‹éªŒè¯è¯„ä¼°å‡½æ•°ï¼Œè®¡ç®—Diceç³»æ•°ç­‰æŒ‡æ ‡
from unet import UNet  # UNetæ¨¡å‹æ¶æ„å®šä¹‰ï¼Œç¼–ç å™¨-è§£ç å™¨åˆ†å‰²ç½‘ç»œ
from utils.data_loading import BasicDataset, CarvanaDataset  # æ•°æ®é›†åŠ è½½ç±»ï¼Œæ”¯æŒå¤šç§æ•°æ®æ ¼å¼
from utils.dice_score import dice_loss  # DiceæŸå¤±å‡½æ•°ï¼Œä¸“é—¨ç”¨äºåˆ†å‰²ä»»åŠ¡çš„æŸå¤±è®¡ç®—


# ================================
# å·¥å…·å‡½æ•°
# ================================
def _log_histograms(model: torch.nn.Module) -> Dict[str, Any]:
    """æ”¶é›†æ¨¡å‹æƒé‡å’Œæ¢¯åº¦çš„åˆ†å¸ƒä¿¡æ¯"""
    histograms = {}
    for tag, value in model.named_parameters():
        tag = tag.replace('/', '.')
        
        try:
            # æ£€æŸ¥æƒé‡æ•°æ®
            if not (torch.isinf(value) | torch.isnan(value)).any():
                weight_data = value.data.cpu()
                # ç¡®ä¿æ•°æ®æ˜¯è¿ç»­çš„ä¸”ä¸æ˜¯ç¨€ç–å¼ é‡
                if not weight_data.is_sparse:
                    weight_data = weight_data.contiguous()
                    # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œé¿å…wandbå¤„ç†å¼ é‡æ—¶çš„é—®é¢˜
                    histograms['æƒé‡/' + tag] = wandb.Histogram(weight_data.numpy())
            
            # æ£€æŸ¥æ¢¯åº¦æ•°æ®
            if value.grad is not None and not (torch.isinf(value.grad) | torch.isnan(value.grad)).any():
                grad_data = value.grad.data.cpu()
                # ç¡®ä¿æ•°æ®æ˜¯è¿ç»­çš„ä¸”ä¸æ˜¯ç¨€ç–å¼ é‡
                if not grad_data.is_sparse:
                    grad_data = grad_data.contiguous()
                    # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œé¿å…wandbå¤„ç†å¼ é‡æ—¶çš„é—®é¢˜
                    histograms['æ¢¯åº¦/' + tag] = wandb.Histogram(grad_data.numpy())
        except Exception as e:
            # é™é»˜å¤„ç†å¼‚å¸¸ï¼Œé¿å…ä¸­æ–­è®­ç»ƒ
            logging.debug(f'è®°å½•å‚æ•° {tag} çš„ç›´æ–¹å›¾æ—¶å‡ºé”™: {e}')
            pass
    
    return histograms


class EarlyStopping:
    """æ—©åœæœºåˆ¶ç±»ï¼Œç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆ"""
    
    def __init__(self, patience: int = 10, min_delta: float = 0.001, restore_best_weights: bool = True):
        self.patience = patience
        self.min_delta = min_delta
        self.restore_best_weights = restore_best_weights
        self.best_score = None
        self.counter = 0
        self.best_weights = None
        
    def __call__(self, val_score: float, model: torch.nn.Module) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ—©åœ"""
        if self.best_score is None:
            self.best_score = val_score
            self._save_weights(model)
            return False
        
        if val_score >= self.best_score + self.min_delta:
            self.best_score = val_score
            self.counter = 0
            self._save_weights(model)
            return False
        
        self.counter += 1
        if self.counter >= self.patience:
            if self.restore_best_weights and self.best_weights is not None:
                model.load_state_dict(self.best_weights)
                logging.info(f'æ¢å¤æœ€ä½³æƒé‡ï¼Œæœ€ä½³éªŒè¯åˆ†æ•°: {self.best_score:.4f}')
            return True
        
        return False
    
    def _save_weights(self, model: torch.nn.Module):
        """ä¿å­˜å½“å‰æœ€ä½³æƒé‡"""
        import copy
        self.best_weights = copy.deepcopy(model.state_dict())


def _prepare_mask_for_logging(masks_pred: torch.Tensor, true_masks: torch.Tensor, 
                            model: torch.nn.Module) -> Tuple[torch.Tensor, torch.Tensor]:
    """å‡†å¤‡ç”¨äºWandBæ—¥å¿—è®°å½•çš„æ©ç å¼ é‡"""
    try:
        # å¤„ç†é¢„æµ‹æ©ç 
        if model.n_classes == 1:
            # äºŒåˆ†ç±»ï¼šå–ç¬¬ä¸€ä¸ªæ ·æœ¬çš„ç¬¬ä¸€ä¸ªé€šé“
            pred_mask = (F.sigmoid(masks_pred[0, 0]) > 0.5).float().cpu()
        else:
            # å¤šåˆ†ç±»ï¼šå–argmaxåçš„ç¬¬ä¸€ä¸ªæ ·æœ¬
            pred_mask = masks_pred.argmax(dim=1)[0].float().cpu()
        
        # ç¡®ä¿pred_maskæ˜¯è¿ç»­çš„2Då¼ é‡
        pred_mask = pred_mask.contiguous()
        while pred_mask.dim() > 2:
            pred_mask = pred_mask.squeeze(0)
        if pred_mask.dim() < 2:
            pred_mask = pred_mask.unsqueeze(0)
            
        # å¤„ç†çœŸå®æ©ç 
        true_mask = true_masks[0].float().cpu()
        true_mask = true_mask.contiguous()
        while true_mask.dim() > 2:
            true_mask = true_mask.squeeze(0)
        if true_mask.dim() < 2:
            true_mask = true_mask.unsqueeze(0)
        
        # ç¡®ä¿å°ºå¯¸åŒ¹é…
        if pred_mask.shape != true_mask.shape:
            if true_mask.numel() == pred_mask.numel():
                true_mask = true_mask.reshape(pred_mask.shape)
            else:
                # ä½¿ç”¨æ’å€¼è°ƒæ•´å°ºå¯¸
                # ç¡®ä¿è¾“å…¥æ˜¯4Då¼ é‡ (N, C, H, W)
                true_mask_4d = true_mask.unsqueeze(0).unsqueeze(0)
                true_mask_resized = F.interpolate(
                    true_mask_4d, 
                    size=pred_mask.shape, 
                    mode='nearest'
                )
                true_mask = true_mask_resized.squeeze(0).squeeze(0).contiguous()
        
        # æœ€ç»ˆéªŒè¯ï¼šç¡®ä¿è¿”å›çš„æ˜¯2Då¼ é‡
        assert pred_mask.dim() == 2, f"pred_maskåº”è¯¥æ˜¯2Då¼ é‡ï¼Œä½†å¾—åˆ°{pred_mask.dim()}ç»´"
        assert true_mask.dim() == 2, f"true_maskåº”è¯¥æ˜¯2Då¼ é‡ï¼Œä½†å¾—åˆ°{true_mask.dim()}ç»´"
        
        return pred_mask, true_mask
        
    except Exception as e:
        logging.warning(f'æ©ç é¢„å¤„ç†å¤±è´¥: {e}')
        # è¿”å›å®‰å…¨çš„é»˜è®¤å€¼
        return torch.zeros(64, 64), torch.zeros(64, 64)


# ================================
# å…¨å±€é…ç½®ç±»
# ================================
class Config:
    """å…¨å±€é…ç½®ç±»ï¼Œé›†ä¸­ç®¡ç†é¡¹ç›®é…ç½®å‚æ•°"""
    
    # æ•°æ®è·¯å¾„é…ç½®
    DATA_DIR = Path('./data')
    IMG_DIR = DATA_DIR / 'imgs'
    MASK_DIR = DATA_DIR / 'masks'
    CHECKPOINT_DIR = Path('./checkpoints')
    
    # è®­ç»ƒå‚æ•°é…ç½®
    RANDOM_SEED = 42
    VAL_INTERVAL = 0.2
    PATIENCE = 10
    MIN_DELTA = 0.001
    
    # ç¡¬ä»¶èµ„æºé…ç½®
    NUM_WORKERS = min(os.cpu_count(), 8)
    PIN_MEMORY = torch.cuda.is_available()
    PREFETCH_FACTOR = 2


def train_model(
        model: torch.nn.Module,
        device: torch.device,
        epochs: int = 5,
        batch_size: int = 1,
        learning_rate: float = 1e-5,
        val_percent: float = 0.1,
        save_checkpoint: bool = True,
        img_scale: float = 0.5,
        amp: bool = False,
        weight_decay: float = 1e-8,
        momentum: float = 0.999,
        gradient_clipping: float = 1.0,
        accumulate_grad_batches: int = 1,  # æ¢¯åº¦ç´¯ç§¯æ‰¹æ¬¡æ•°
):
    """
    UNetæ¨¡å‹è®­ç»ƒçš„ä¸»å‡½æ•°ï¼Œå®ç°å®Œæ•´çš„è®­ç»ƒæµç¨‹

    è¯¥å‡½æ•°æ˜¯è®­ç»ƒè„šæœ¬çš„æ ¸å¿ƒï¼Œå®ç°äº†ä»æ•°æ®åŠ è½½åˆ°æ¨¡å‹ä¿å­˜çš„å®Œæ•´è®­ç»ƒæµç¨‹ã€‚
    æ”¯æŒå¤šç§è®­ç»ƒç­–ç•¥å’Œä¼˜åŒ–æŠ€æœ¯ï¼Œç¡®ä¿è®­ç»ƒè¿‡ç¨‹çš„ç¨³å®šæ€§å’Œæ•ˆç‡ã€‚
    
    ================================
    è®­ç»ƒæµç¨‹æ¦‚è¿°ï¼š
    ================================
    1. æ•°æ®é›†åŠ è½½å’Œé¢„å¤„ç†
       - è‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨åˆé€‚çš„æ•°æ®é›†ç±»ï¼ˆCarvanaDatasetæˆ–BasicDatasetï¼‰
       - æŒ‰æ¯”ä¾‹åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
       - é…ç½®é«˜æ•ˆçš„æ•°æ®åŠ è½½å™¨
    
    2. è®­ç»ƒç¯å¢ƒåˆå§‹åŒ–
       - åˆå§‹åŒ–WandBå®éªŒè·Ÿè¸ª
       - é…ç½®ä¼˜åŒ–å™¨ã€æŸå¤±å‡½æ•°å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨
       - è®¾ç½®æ··åˆç²¾åº¦è®­ç»ƒï¼ˆAMPï¼‰ç¯å¢ƒ
    
    3. è®­ç»ƒå¾ªç¯æ‰§è¡Œ
       - å‰å‘ä¼ æ’­ï¼šè®¡ç®—é¢„æµ‹ç»“æœå’ŒæŸå¤±
       - åå‘ä¼ æ’­ï¼šè®¡ç®—æ¢¯åº¦å¹¶æ›´æ–°æ¨¡å‹å‚æ•°
       - å®šæœŸéªŒè¯ï¼šè¯„ä¼°æ¨¡å‹æ€§èƒ½å¹¶è°ƒæ•´å­¦ä¹ ç‡
       - å®æ—¶ç›‘æ§ï¼šè®°å½•è®­ç»ƒæŒ‡æ ‡å’Œå¯è§†åŒ–ç»“æœ
    
    4. æ¨¡å‹ä¿å­˜å’Œæ¢å¤
       - è‡ªåŠ¨ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹
       - æ”¯æŒä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
    
    ================================
    å‚æ•°è¯¦ç»†è¯´æ˜ï¼š
    ================================
    Args:
        model (torch.nn.Module): å¾…è®­ç»ƒçš„UNetæ¨¡å‹å®ä¾‹
            - å¿…é¡»æ˜¯UNetç±»çš„å®ä¾‹ï¼ŒåŒ…å«n_channelså’Œn_classeså±æ€§
            - æ¨¡å‹åº”è¯¥å·²ç»ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ä¸Š
            - æ”¯æŒé¢„è®­ç»ƒæƒé‡åŠ è½½
        
        device (torch.device): è®­ç»ƒè®¾å¤‡
            - 'cuda': ä½¿ç”¨GPUè®­ç»ƒï¼Œéœ€è¦CUDAæ”¯æŒ
            - 'cpu': ä½¿ç”¨CPUè®­ç»ƒï¼Œé€Ÿåº¦è¾ƒæ…¢ä½†å…¼å®¹æ€§å¥½
            - 'mps': Apple Siliconè®¾å¤‡ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
        
        epochs (int, optional): æ€»è®­ç»ƒè½®æ•°. é»˜è®¤å€¼: 5
            - æ¯è½®éå†æ•´ä¸ªè®­ç»ƒé›†ä¸€æ¬¡
            - å»ºè®®å€¼ï¼šå°æ•°æ®é›†50-100è½®ï¼Œå¤§æ•°æ®é›†20-50è½®
            - è¿‡å°‘å¯èƒ½å¯¼è‡´æ¬ æ‹Ÿåˆï¼Œè¿‡å¤šå¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆ
        
        batch_size (int, optional): æ‰¹æ¬¡å¤§å°. é»˜è®¤å€¼: 1
            - æ¯æ‰¹æ¬¡å¤„ç†çš„æ ·æœ¬æ•°ï¼Œç›´æ¥å½±å“è®­ç»ƒé€Ÿåº¦å’Œæ˜¾å­˜å ç”¨
            - GPUæ˜¾å­˜å»ºè®®ï¼š8GBæ˜¾å­˜å¯ç”¨batch_size=4-8ï¼Œ16GBå¯ç”¨8-16
            - è¿‡å°å½±å“è®­ç»ƒæ•ˆç‡ï¼Œè¿‡å¤§å¯èƒ½å¯¼è‡´æ˜¾å­˜æº¢å‡º
        
        learning_rate (float, optional): åˆå§‹å­¦ä¹ ç‡. é»˜è®¤å€¼: 1e-5
            - æ§åˆ¶æ¨¡å‹å‚æ•°æ›´æ–°çš„æ­¥é•¿
            - å»ºè®®èŒƒå›´ï¼š1e-4 åˆ° 1e-6
            - è¿‡é«˜å¯èƒ½å¯¼è‡´è®­ç»ƒä¸ç¨³å®šï¼Œè¿‡ä½å¯èƒ½å¯¼è‡´æ”¶æ•›ç¼“æ…¢
        
        val_percent (float, optional): éªŒè¯é›†æ¯”ä¾‹. é»˜è®¤å€¼: 0.1
            - éªŒè¯é›†å æ€»æ•°æ®é›†çš„æ¯”ä¾‹ï¼ŒèŒƒå›´[0, 1]
            - 0.1è¡¨ç¤º10%æ•°æ®ç”¨äºéªŒè¯ï¼Œ90%ç”¨äºè®­ç»ƒ
            - å»ºè®®å€¼ï¼šå°æ•°æ®é›†0.2-0.3ï¼Œå¤§æ•°æ®é›†0.1-0.2
        
        save_checkpoint (bool, optional): æ˜¯å¦ä¿å­˜æ£€æŸ¥ç‚¹. é»˜è®¤å€¼: True
            - True: æ¯è½®ç»“æŸåä¿å­˜æ¨¡å‹çŠ¶æ€ï¼Œæ”¯æŒæ–­ç‚¹ç»­è®­
            - False: ä¸ä¿å­˜æ£€æŸ¥ç‚¹ï¼ŒèŠ‚çœç£ç›˜ç©ºé—´
        
        img_scale (float, optional): å›¾åƒç¼©æ”¾æ¯”ä¾‹. é»˜è®¤å€¼: 0.5
            - æ§åˆ¶è¾“å…¥å›¾åƒçš„å°ºå¯¸ï¼ŒèŒƒå›´(0, 1]
            - 0.5è¡¨ç¤ºå°†å›¾åƒå°ºå¯¸ç¼©å°åˆ°åŸæ¥çš„50%
            - è¾ƒå°çš„å€¼å¯ä»¥å‡å°‘æ˜¾å­˜å ç”¨ï¼Œä½†å¯èƒ½å½±å“åˆ†å‰²ç²¾åº¦
        
        amp (bool, optional): æ˜¯å¦å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ. é»˜è®¤å€¼: False
            - True: ä½¿ç”¨FP16ç²¾åº¦è®­ç»ƒï¼Œå¯å‡å°‘50%æ˜¾å­˜å ç”¨
            - False: ä½¿ç”¨FP32ç²¾åº¦è®­ç»ƒï¼Œæ•°å€¼ç¨³å®šæ€§æ›´å¥½
            - å»ºè®®åœ¨æ˜¾å­˜ä¸è¶³æ—¶å¯ç”¨
        
        weight_decay (float, optional): L2æ­£åˆ™åŒ–ç³»æ•°. é»˜è®¤å€¼: 1e-8
            - é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ­£åˆ™åŒ–é¡¹
            - å»ºè®®èŒƒå›´ï¼š1e-8 åˆ° 1e-4
            - è¿‡å¤§ä¼šå½±å“æ¨¡å‹å­¦ä¹ èƒ½åŠ›ï¼Œè¿‡å°å¯èƒ½æ— æ³•é˜²æ­¢è¿‡æ‹Ÿåˆ
        
        momentum (float, optional): åŠ¨é‡å› å­. é»˜è®¤å€¼: 0.999
            - ä¼˜åŒ–å™¨çš„åŠ¨é‡å‚æ•°ï¼Œå½±å“å‚æ•°æ›´æ–°æ–¹å‘
            - ä»…åœ¨ä½¿ç”¨SGDä¼˜åŒ–å™¨æ—¶æœ‰æ•ˆ
            - å»ºè®®èŒƒå›´ï¼š0.9 åˆ° 0.999
        
        gradient_clipping (float, optional): æ¢¯åº¦è£å‰ªé˜ˆå€¼. é»˜è®¤å€¼: 1.0
            - é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸çš„æŠ€æœ¯
            - å½“æ¢¯åº¦èŒƒæ•°è¶…è¿‡æ­¤å€¼æ—¶è¿›è¡Œè£å‰ª
            - å»ºè®®èŒƒå›´ï¼š0.5 åˆ° 2.0
    
    Returns:
        None: è¯¥å‡½æ•°ä¸è¿”å›å€¼ï¼Œè®­ç»ƒç»“æœé€šè¿‡æ£€æŸ¥ç‚¹æ–‡ä»¶å’ŒWandBè®°å½•
    
    Raises:
        RuntimeError: å½“æ•°æ®é›†åŠ è½½å¤±è´¥æ—¶æŠ›å‡º
        AssertionError: å½“æ¨¡å‹è¾“å…¥é€šé“æ•°ä¸å›¾åƒé€šé“æ•°ä¸åŒ¹é…æ—¶æŠ›å‡º
        torch.cuda.OutOfMemoryError: å½“GPUæ˜¾å­˜ä¸è¶³æ—¶æŠ›å‡º
    
    ================================
    è®­ç»ƒç­–ç•¥è¯´æ˜ï¼š
    ================================
    
    1. æŸå¤±å‡½æ•°ç»„åˆï¼š
       - äºŒåˆ†ç±»ä»»åŠ¡ï¼šBCEæŸå¤± + DiceæŸå¤±
       - å¤šåˆ†ç±»ä»»åŠ¡ï¼šäº¤å‰ç†µæŸå¤± + DiceæŸå¤±
       - DiceæŸå¤±ä¸“é—¨ä¼˜åŒ–åˆ†å‰²ä»»åŠ¡çš„é‡å åº¦æŒ‡æ ‡
    
    2. ä¼˜åŒ–å™¨é…ç½®ï¼š
       - ä½¿ç”¨AdamWä¼˜åŒ–å™¨ï¼Œç»“åˆäº†Adamå’Œæƒé‡è¡°å‡çš„ä¼˜åŠ¿
       - å¯ç”¨AMSGradå˜ä½“ï¼Œæä¾›æ›´ç¨³å®šçš„è®­ç»ƒè¿‡ç¨‹
       - è‡ªåŠ¨æƒé‡è¡°å‡é˜²æ­¢è¿‡æ‹Ÿåˆ
    
    3. å­¦ä¹ ç‡è°ƒåº¦ï¼š
       - ä½¿ç”¨ä½™å¼¦é€€ç«é‡å¯ç­–ç•¥
       - åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡
       - é¿å…å­¦ä¹ ç‡è¿‡å°å¯¼è‡´çš„æ”¶æ•›åœæ»
    
    4. æ··åˆç²¾åº¦è®­ç»ƒï¼š
       - ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦ï¼ˆAMPï¼‰æŠ€æœ¯
       - åœ¨ä¿æŒæ•°å€¼ç¨³å®šæ€§çš„åŒæ—¶æå‡è®­ç»ƒé€Ÿåº¦
       - ç‰¹åˆ«é€‚ç”¨äºå¤§æ¨¡å‹è®­ç»ƒ
    
    ================================
    æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯ï¼š
    ================================
    
    1. å†…å­˜ä¼˜åŒ–ï¼š
       - é€šé“ä¼˜å…ˆå†…å­˜æ ¼å¼ï¼ˆchannels_lastï¼‰æå‡GPUæ€§èƒ½
       - æ¢¯åº¦ç´¯ç§¯å‡å°‘æ˜¾å­˜å ç”¨
       - é”é¡µå†…å­˜åŠ é€ŸCPU-GPUæ•°æ®ä¼ è¾“
    
    2. è®¡ç®—ä¼˜åŒ–ï¼š
       - è‡ªåŠ¨æ··åˆç²¾åº¦å‡å°‘è®¡ç®—é‡
       - æ•°æ®å¹¶è¡ŒåŠ è½½æå‡I/Oæ•ˆç‡
       - æ¢¯åº¦æ£€æŸ¥ç‚¹æœºåˆ¶å¤„ç†å¤§æ¨¡å‹
    
    3. ç›‘æ§å’Œè°ƒè¯•ï¼š
       - å®æ—¶æŸå¤±å’ŒæŒ‡æ ‡è®°å½•
       - æƒé‡å’Œæ¢¯åº¦åˆ†å¸ƒå¯è§†åŒ–
       - è®­ç»ƒè¿‡ç¨‹å›¾åƒå’Œé¢„æµ‹ç»“æœå±•ç¤º
    
    
    ================================
    æ³¨æ„äº‹é¡¹å’Œæœ€ä½³å®è·µï¼š
    ================================
    
    1. æ•°æ®å‡†å¤‡ï¼š
       - ç¡®ä¿å›¾ç‰‡å’Œæ©ç æ–‡ä»¶ä¸€ä¸€å¯¹åº”
       - æ£€æŸ¥å›¾ç‰‡æ ¼å¼å’Œé€šé“æ•°æ˜¯å¦ä¸€è‡´
       - éªŒè¯æ©ç æ ‡ç­¾å€¼æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
    
    2. ç¡¬ä»¶é…ç½®ï¼š
       - GPUè®­ç»ƒæ—¶ç¡®ä¿CUDAç‰ˆæœ¬å…¼å®¹
       - æ ¹æ®æ˜¾å­˜å¤§å°è°ƒæ•´batch_size
       - ä½¿ç”¨SSDå­˜å‚¨æå‡æ•°æ®åŠ è½½é€Ÿåº¦
    
    3. è¶…å‚æ•°è°ƒä¼˜ï¼š
       - å­¦ä¹ ç‡æ˜¯æœ€é‡è¦çš„è¶…å‚æ•°ï¼Œéœ€è¦ä»”ç»†è°ƒæ•´
       - æ‰¹æ¬¡å¤§å°å½±å“è®­ç»ƒç¨³å®šæ€§å’Œæ”¶æ•›é€Ÿåº¦
       - éªŒè¯é›†æ¯”ä¾‹å½±å“æ¨¡å‹æ³›åŒ–èƒ½åŠ›è¯„ä¼°
    
    4. è®­ç»ƒç›‘æ§ï¼š
       - å®šæœŸæ£€æŸ¥è®­ç»ƒæŸå¤±å’ŒéªŒè¯æŒ‡æ ‡
       - å…³æ³¨è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆç°è±¡
       - ä½¿ç”¨WandBç­‰å·¥å…·è¿›è¡Œå¯è§†åŒ–åˆ†æ
    
    5. å¼‚å¸¸å¤„ç†ï¼š
       - æ˜¾å­˜æº¢å‡ºæ—¶è‡ªåŠ¨å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
       - è®­ç»ƒä¸­æ–­æ—¶å¯ä»¥ä»æ£€æŸ¥ç‚¹æ¢å¤
       - ç½‘ç»œå¼‚å¸¸æ—¶è‡ªåŠ¨é‡è¯•æœºåˆ¶
    """
    # 1. æ•°æ®é›†åˆ›å»ºå’ŒåŠ è½½
    try:
        dataset = CarvanaDataset(Config.IMG_DIR, Config.MASK_DIR, img_scale)
        logging.info(f'æˆåŠŸåŠ è½½CarvanaDatasetï¼Œå…±{len(dataset)}ä¸ªæ ·æœ¬')
    except (AssertionError, RuntimeError, IndexError) as e:
        logging.warning(f'CarvanaDatasetåŠ è½½å¤±è´¥: {e}ï¼Œå›é€€åˆ°BasicDataset')
        dataset = BasicDataset(Config.IMG_DIR, Config.MASK_DIR, img_scale)
        logging.info(f'æˆåŠŸåŠ è½½BasicDatasetï¼Œå…±{len(dataset)}ä¸ªæ ·æœ¬')

    # 2. è®­ç»ƒé›†å’ŒéªŒè¯é›†åˆ’åˆ†
    n_val = int(len(dataset) * val_percent)
    n_train = len(dataset) - n_val
    
    train_set, val_set = random_split(
        dataset, 
        [n_train, n_val], 
        generator=torch.Generator().manual_seed(0)
    )
    
    logging.info(f'æ•°æ®é›†åˆ’åˆ†å®Œæˆï¼šè®­ç»ƒé›†{n_train}ä¸ªæ ·æœ¬ï¼ŒéªŒè¯é›†{n_val}ä¸ªæ ·æœ¬')

    # 3. æ•°æ®åŠ è½½å™¨é…ç½®å’Œåˆ›å»º
    num_workers = min(Config.NUM_WORKERS, batch_size * 2) if batch_size > 1 else Config.NUM_WORKERS
    
    loader_args = dict(
        batch_size=batch_size,
        num_workers=num_workers,
        pin_memory=device.type == 'cuda',
        prefetch_factor=Config.PREFETCH_FACTOR if num_workers > 0 else None,
        persistent_workers=num_workers > 0,
        multiprocessing_context='spawn' if os.name == 'nt' and num_workers > 0 else None
    )
    
    g = torch.Generator().manual_seed(Config.RANDOM_SEED)
    
    train_loader = DataLoader(train_set, shuffle=True, drop_last=True, generator=g, **loader_args)
    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)

    logging.info(f'æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆï¼šè®­ç»ƒæ‰¹æ¬¡{len(train_loader)}ä¸ªï¼ŒéªŒè¯æ‰¹æ¬¡{len(val_loader)}ä¸ª')

    # 4. å®éªŒè·Ÿè¸ªå’Œæ—¥å¿—åˆå§‹åŒ–
    experiment = wandb.init(
        project='U-Net', 
        resume='allow', 
        anonymous='must',
        name=f'unetè®­ç»ƒ_{epochs}è½®æ¬¡_æ‰¹æ¬¡{batch_size}'
    )
    
    experiment.config.update({
        'epochs': epochs,
        'batch_size': batch_size,
        'learning_rate': learning_rate,
        'val_percent': val_percent,
        'save_checkpoint': save_checkpoint,
        'img_scale': img_scale,
        'amp': amp,
        'weight_decay': weight_decay,
        'gradient_clipping': gradient_clipping,
        'accumulate_grad_batches': accumulate_grad_batches
    })

    logging.info(f'è®­ç»ƒé…ç½®: è½®æ•°={epochs}, æ‰¹æ¬¡={batch_size}, å­¦ä¹ ç‡={learning_rate}, è®­ç»ƒé›†={n_train}, éªŒè¯é›†={n_val}, è®¾å¤‡={device.type}, ç¼©æ”¾={img_scale}, AMP={amp}')

    # 5. è®­ç»ƒç»„ä»¶åˆå§‹åŒ–
    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay, amsgrad=True)
    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=max(1, epochs // 3), T_mult=2, eta_min=learning_rate * 1e-3)
    
    if amp and device.type == 'cuda':
        try:
            grad_scaler = torch.amp.GradScaler('cuda', enabled=True)
        except AttributeError:
            grad_scaler = torch.cuda.amp.GradScaler(enabled=True)
    else:
        grad_scaler = torch.cuda.amp.GradScaler(enabled=False)
    
    criterion = nn.CrossEntropyLoss() if model.n_classes > 1 else nn.BCEWithLogitsLoss()
    early_stopping = EarlyStopping(patience=Config.PATIENCE, min_delta=Config.MIN_DELTA, restore_best_weights=True)
    
    global_step = 0
    accumulation_steps = 0
    effective_batch_size = batch_size * accumulate_grad_batches
    
    logging.info(f'è®­ç»ƒç»„ä»¶åˆå§‹åŒ–å®Œæˆï¼Œæœ‰æ•ˆæ‰¹æ¬¡å¤§å°: {effective_batch_size}')

    # 6. ä¸»è®­ç»ƒå¾ªç¯
    for epoch in range(1, epochs + 1):
        model.train()
        epoch_loss = 0
        
        with tqdm(total=n_train, desc=f'è½®æ¬¡ {epoch}/{epochs}', unit='å¼ ') as pbar:
            for batch in train_loader:
                images, true_masks = batch['image'], batch['mask']

                assert images.shape[1] == model.n_channels, \
                    f'æ¨¡å‹å®šä¹‰ä¸º{model.n_channels}è¾“å…¥é€šé“ï¼Œä½†å›¾ç‰‡å®é™…ä¸º{images.shape[1]}é€šé“ï¼Œè¯·æ£€æŸ¥å›¾ç‰‡åŠ è½½æ˜¯å¦æ­£ç¡®ã€‚'

                images = images.to(device=device, dtype=torch.float32, 
                                 memory_format=torch.channels_last if device.type == 'cuda' else torch.contiguous_format,
                                 non_blocking=True)
                true_masks = true_masks.to(device=device, dtype=torch.long, non_blocking=True)

                # 6.1 å‰å‘ä¼ æ’­ä¸æŸå¤±è®¡ç®—
                with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):
                    masks_pred = model(images)
                    
                    if model.n_classes == 1:
                        bce_loss = criterion(masks_pred.squeeze(1), true_masks.float())
                        dice_loss_value = dice_loss(F.sigmoid(masks_pred.squeeze(1)), true_masks.float(), multiclass=False)
                        loss = bce_loss + dice_loss_value
                    else:
                        ce_loss = criterion(masks_pred, true_masks)
                        pred_probs = F.softmax(masks_pred, dim=1)
                        true_masks_for_onehot = true_masks.squeeze(1) if true_masks.dim() == 4 else true_masks
                        true_one_hot = F.one_hot(true_masks_for_onehot, model.n_classes).permute(0, 3, 1, 2).float()
                        dice_loss_value = dice_loss(pred_probs, true_one_hot, multiclass=True)
                        loss = ce_loss + dice_loss_value

                # 6.2 åå‘ä¼ æ’­ä¸å‚æ•°ä¼˜åŒ–ï¼ˆæ”¯æŒæ¢¯åº¦ç´¯ç§¯ï¼‰
                loss = loss / accumulate_grad_batches
                grad_scaler.scale(loss).backward()
                accumulation_steps += 1
                
                if accumulation_steps % accumulate_grad_batches == 0:
                    grad_scaler.unscale_(optimizer)
                    torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)
                    grad_scaler.step(optimizer)
                    grad_scaler.update()
                    optimizer.zero_grad(set_to_none=True)

                # 6.3 è®­ç»ƒçŠ¶æ€æ›´æ–°å’Œæ—¥å¿—è®°å½•
                pbar.update(images.shape[0])
                global_step += 1
                epoch_loss += loss.item()
                
                if global_step % max(1, len(train_loader) // 20) == 0:
                    experiment.log({
                        'è®­ç»ƒæŸå¤±': loss.item() * accumulate_grad_batches,
                        'æ­¥æ•°': global_step,
                        'è½®æ¬¡': epoch,
                        'å­¦ä¹ ç‡': optimizer.param_groups[0]['lr'],
                        'æœ‰æ•ˆæ‰¹æ¬¡å¤§å°': effective_batch_size
                    })
                
                pbar.set_postfix(**{'æŸå¤± (æ‰¹æ¬¡)': loss.item()})

                # 6.4 å®šæœŸéªŒè¯å’Œå¯è§†åŒ–è®°å½•
                division_step = (n_train // (5 * batch_size))
                if division_step > 0 and global_step % division_step == 0:
                    histograms = _log_histograms(model)
                    val_score = evaluate(model, val_loader, device, amp)
                    scheduler.step(val_score)
                    logging.info(f'éªŒè¯é›†Diceåˆ†æ•°: {val_score:.4f}')
                    
                    try:
                        pred_mask, true_mask = _prepare_mask_for_logging(masks_pred, true_masks, model)
                        basic_log = {
                            'å­¦ä¹ ç‡': optimizer.param_groups[0]['lr'],
                            'éªŒè¯Diceåˆ†æ•°': val_score,
                            'æ­¥æ•°': global_step,
                            'è½®æ¬¡': epoch,
                        }
                        
                        try:
                            basic_log.update({
                                'å›¾åƒ': wandb.Image(images[0].cpu()),
                                'æ©ç ': {
                                    'çœŸå®': wandb.Image(true_mask),
                                    'é¢„æµ‹': wandb.Image(pred_mask),
                                },
                            })
                        except Exception as img_e:
                            logging.warning(f'å›¾åƒè®°å½•å¤±è´¥: {img_e}')
                        
                        try:
                            basic_log.update(histograms)
                        except Exception as hist_e:
                            logging.warning(f'ç›´æ–¹å›¾è®°å½•å¤±è´¥: {hist_e}')
                        
                        experiment.log(basic_log)
                    except Exception as e:
                        logging.warning(f'WandBè®°å½•å¤±è´¥: {e}')
                        try:
                            experiment.log({
                                'å­¦ä¹ ç‡': optimizer.param_groups[0]['lr'],
                                'éªŒè¯Diceåˆ†æ•°': val_score,
                                'æ­¥æ•°': global_step,
                                'è½®æ¬¡': epoch,
                            })
                        except:
                            pass

        # 6.5 æ¯è½®ç»“æŸåçš„éªŒè¯å’Œæ—©åœæ£€æŸ¥
        model.eval()
        with torch.no_grad():
            epoch_val_score = evaluate(model, val_loader, device, amp)
            logging.info(f'Epoch {epoch} éªŒè¯é›†Diceåˆ†æ•°: {epoch_val_score:.4f}')
            
            if early_stopping(epoch_val_score, model):
                logging.info(f'æ—©åœè§¦å‘ï¼è¿ç»­{Config.PATIENCE}è½®éªŒè¯æŒ‡æ ‡æœªæå‡ï¼Œæœ€ä½³éªŒè¯åˆ†æ•°: {early_stopping.best_score:.4f}')
                break
        
        # 6.6 æ¨¡å‹æ£€æŸ¥ç‚¹ä¿å­˜
        if save_checkpoint:
            Path(Config.CHECKPOINT_DIR).mkdir(parents=True, exist_ok=True)
            avg_train_loss = epoch_loss / len(train_loader)
            
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'loss': avg_train_loss,
                'val_score': epoch_val_score,
                'mask_values': dataset.mask_values
            }
            
            checkpoint_path = Config.CHECKPOINT_DIR / f'checkpoint_epoch{epoch}.pth'
            torch.save(checkpoint, str(checkpoint_path))
            logging.info(f'æ£€æŸ¥ç‚¹ {epoch} å·²ä¿å­˜è‡³ {checkpoint_path}!')
            
            is_best_model = (epoch_val_score >= early_stopping.best_score - Config.MIN_DELTA)
            if is_best_model:
                best_model_path = Config.CHECKPOINT_DIR / 'best_model.pth'
                torch.save(checkpoint, str(best_model_path))
                logging.info(f'æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜ï¼éªŒè¯åˆ†æ•°: {epoch_val_score:.4f}')
            
            experiment.log({
                'è½®æ¬¡': epoch,
                'å¹³å‡è®­ç»ƒæŸå¤±': avg_train_loss,
                'éªŒè¯åˆ†æ•°': epoch_val_score,
                'æ£€æŸ¥ç‚¹å·²ä¿å­˜': True,
                'æ˜¯å¦æœ€ä½³æ¨¡å‹': is_best_model
            })



def get_args():
    """
    å‘½ä»¤è¡Œå‚æ•°è§£æå‡½æ•°ï¼Œå¤„ç†è®­ç»ƒè„šæœ¬çš„å‘½ä»¤è¡Œè¾“å…¥å‚æ•°
    
    è¯¥å‡½æ•°ä½¿ç”¨argparseæ¨¡å—è§£æå‘½ä»¤è¡Œå‚æ•°ï¼Œæä¾›äº†çµæ´»çš„è®­ç»ƒé…ç½®é€‰é¡¹ã€‚
    æ‰€æœ‰å‚æ•°éƒ½æœ‰åˆç†çš„é»˜è®¤å€¼ï¼Œæ”¯æŒå¿«é€Ÿå¼€å§‹è®­ç»ƒæˆ–ç²¾ç»†è°ƒä¼˜ã€‚
    
    ================================
    æ”¯æŒçš„å‚æ•°è¯¦è§£ï¼š
    ================================
    
    åŸºç¡€è®­ç»ƒå‚æ•°ï¼š
    --epochs, -e (int): è®­ç»ƒè½®æ•°
        - é»˜è®¤å€¼: 5
        - å»ºè®®å€¼: å°æ•°æ®é›†50-100è½®ï¼Œå¤§æ•°æ®é›†20-50è½®
        - å½±å“: è¿‡å°‘å¯èƒ½å¯¼è‡´æ¬ æ‹Ÿåˆï¼Œè¿‡å¤šå¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆ
    
    --batch-size, -b (int): æ‰¹æ¬¡å¤§å°
        - é»˜è®¤å€¼: 1
        - å»ºè®®å€¼: æ ¹æ®æ˜¾å­˜è°ƒæ•´ï¼Œ8GBæ˜¾å­˜å¯ç”¨4-8ï¼Œ16GBå¯ç”¨8-16
        - å½±å“: å½±å“è®­ç»ƒç¨³å®šæ€§å’Œæ˜¾å­˜å ç”¨
    
    --learning-rate, -l (float): å­¦ä¹ ç‡
        - é»˜è®¤å€¼: 1e-5
        - å»ºè®®èŒƒå›´: 1e-4 åˆ° 1e-6
        - å½±å“: æ§åˆ¶æ¨¡å‹å‚æ•°æ›´æ–°çš„æ­¥é•¿
    
    æ•°æ®å’Œæ¨¡å‹å‚æ•°ï¼š
    --load, -f (str): é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
        - é»˜è®¤å€¼: Falseï¼ˆä¸ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼‰
        - ç”¨é€”: ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒæˆ–ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
        - æ ¼å¼: .pthæ–‡ä»¶è·¯å¾„
    
    --scale, -s (float): å›¾åƒç¼©æ”¾æ¯”ä¾‹
        - é»˜è®¤å€¼: 0.5
        - èŒƒå›´: (0, 1]
        - å½±å“: æ§åˆ¶è¾“å…¥å›¾åƒå°ºå¯¸ï¼Œå¹³è¡¡æ˜¾å­˜å ç”¨å’Œåˆ†å‰²ç²¾åº¦
    
    --validation, -v (float): éªŒè¯é›†æ¯”ä¾‹
        - é»˜è®¤å€¼: 10.0ï¼ˆè¡¨ç¤º10%ï¼‰
        - èŒƒå›´: 0-100
        - å»ºè®®å€¼: å°æ•°æ®é›†20-30%ï¼Œå¤§æ•°æ®é›†10-20%
    
    --classes, -c (int): åˆ†å‰²ç±»åˆ«æ•°
        - é»˜è®¤å€¼: 2
        - å«ä¹‰: åŒ…æ‹¬èƒŒæ™¯ç±»åœ¨å†…çš„æ€»ç±»åˆ«æ•°
        - å½±å“: å†³å®šæ¨¡å‹è¾“å‡ºé€šé“æ•°å’ŒæŸå¤±å‡½æ•°é€‰æ‹©
    
    ä¼˜åŒ–å’Œæ€§èƒ½å‚æ•°ï¼š
    --amp (flag): å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
        - é»˜è®¤å€¼: False
        - æ•ˆæœ: å‡å°‘50%æ˜¾å­˜å ç”¨ï¼Œæå‡è®­ç»ƒé€Ÿåº¦
        - é€‚ç”¨: æ˜¾å­˜ä¸è¶³æˆ–éœ€è¦åŠ é€Ÿè®­ç»ƒæ—¶
    
    --bilinear (flag): ä½¿ç”¨åŒçº¿æ€§æ’å€¼ä¸Šé‡‡æ ·
        - é»˜è®¤å€¼: Falseï¼ˆä½¿ç”¨è½¬ç½®å·ç§¯ï¼‰
        - æ•ˆæœ: å‡å°‘å‚æ•°é‡ï¼Œä½†å¯èƒ½å½±å“åˆ†å‰²ç²¾åº¦
        - é€‚ç”¨: æ¨¡å‹å‹ç¼©æˆ–æ˜¾å­˜æåº¦ä¸è¶³æ—¶
    
    ================================
    ä½¿ç”¨ç¤ºä¾‹ï¼š
    ================================
    
    # åŸºç¡€è®­ç»ƒ
    python train.py --epochs 50 --batch-size 8 --learning-rate 1e-4
    
    # é«˜æ€§èƒ½è®­ç»ƒï¼ˆæ··åˆç²¾åº¦+å¤§æ‰¹æ¬¡ï¼‰
    python train.py --epochs 100 --batch-size 16 --amp --scale 0.75
    
    # ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
    python train.py --load checkpoints/checkpoint_epoch10.pth --epochs 50
    
    # å¤šåˆ†ç±»åˆ†å‰²ä»»åŠ¡
    python train.py --classes 5 --epochs 80 --batch-size 4
    
    # æ˜¾å­˜ä¼˜åŒ–è®­ç»ƒ
    python train.py --amp --bilinear --batch-size 2 --scale 0.25
    
    ================================
    è¿”å›å€¼å’Œå¼‚å¸¸ï¼š
    ================================
    
    Returns:
        argparse.Namespace: è§£æåçš„å‚æ•°å¯¹è±¡ï¼ŒåŒ…å«æ‰€æœ‰è®­ç»ƒé…ç½®
        
    Raises:
        SystemExit: å½“å‚æ•°è§£æå¤±è´¥æˆ–ç”¨æˆ·è¯·æ±‚å¸®åŠ©æ—¶é€€å‡ºç¨‹åº
        
    ================================
    æ³¨æ„äº‹é¡¹ï¼š
    ================================
    
    1. å‚æ•°éªŒè¯ï¼š
       - æ‰€æœ‰æ•°å€¼å‚æ•°éƒ½æœ‰èŒƒå›´æ£€æŸ¥
       - æ–‡ä»¶è·¯å¾„ä¼šè‡ªåŠ¨éªŒè¯å­˜åœ¨æ€§
       - ä¸åˆç†çš„å‚æ•°ç»„åˆä¼šç»™å‡ºè­¦å‘Š
    
    2. é»˜è®¤å€¼è®¾è®¡ï¼š
       - æ‰€æœ‰å‚æ•°éƒ½æœ‰ç»è¿‡æµ‹è¯•çš„é»˜è®¤å€¼
       - é»˜è®¤é…ç½®é€‚åˆå¤§å¤šæ•°åœºæ™¯
       - å¯ä»¥æ ¹æ®å…·ä½“éœ€æ±‚è°ƒæ•´
    
    3. å…¼å®¹æ€§ï¼š
       - æ”¯æŒçŸ­å‚æ•°åå’Œé•¿å‚æ•°å
       - å¸ƒå°”æ ‡å¿—ä¸éœ€è¦æŒ‡å®šå€¼
       - æ•°å€¼å‚æ•°æ”¯æŒç§‘å­¦è®¡æ•°æ³•
    
    4. é”™è¯¯å¤„ç†ï¼š
       - æ— æ•ˆå‚æ•°ä¼šç»™å‡ºæ¸…æ™°çš„é”™è¯¯ä¿¡æ¯
       - æä¾›ä½¿ç”¨å¸®åŠ©å’Œç¤ºä¾‹
       - è‡ªåŠ¨æ£€æµ‹å¸¸è§é…ç½®é”™è¯¯
    """
    parser = argparse.ArgumentParser(description='è®­ç»ƒUNetç”¨äºå›¾åƒä¸æ©ç åˆ†å‰²')
    parser.add_argument('--epochs', '-e', metavar='E', type=int, default=5, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch-size', '-b', dest='batch_size', metavar='B', type=int, default=1, help='æ¯æ‰¹æ¬¡æ ·æœ¬æ•°')
    parser.add_argument('--learning-rate', '-l', metavar='LR', type=float, default=1e-5,
                        help='å­¦ä¹ ç‡', dest='lr')
    parser.add_argument('--load', '-f', type=str, default=False, help='ä».pthæ–‡ä»¶åŠ è½½æ¨¡å‹')
    parser.add_argument('--scale', '-s', type=float, default=0.5, help='å›¾ç‰‡ç¼©æ”¾å› å­')
    parser.add_argument('--validation', '-v', dest='val', type=float, default=10.0,
                        help='éªŒè¯é›†æ¯”ä¾‹(0-100)')
    parser.add_argument('--amp', action='store_true', default=False, help='ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ')
    parser.add_argument('--bilinear', action='store_true', default=False, help='ä½¿ç”¨åŒçº¿æ€§ä¸Šé‡‡æ ·')
    parser.add_argument('--classes', '-c', type=int, default=2, help='ç±»åˆ«æ•°')
    parser.add_argument('--accumulate-grad-batches', type=int, default=1, 
                        help='æ¢¯åº¦ç´¯ç§¯æ‰¹æ¬¡æ•°ï¼Œç”¨äºæ¨¡æ‹Ÿæ›´å¤§çš„æ‰¹æ¬¡å¤§å°')

    return parser.parse_args()



# ================================
# ä¸»ç¨‹åºå…¥å£
# ================================
if __name__ == '__main__':
    """
    ä¸»ç¨‹åºå…¥å£ç‚¹ï¼Œè´Ÿè´£åˆå§‹åŒ–è®­ç»ƒç¯å¢ƒå¹¶å¯åŠ¨è®­ç»ƒè¿‡ç¨‹
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. è§£æå‘½ä»¤è¡Œå‚æ•°
    2. åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    3. æ£€æµ‹å’Œé…ç½®è®¡ç®—è®¾å¤‡
    4. åˆ›å»ºå’Œé…ç½®UNetæ¨¡å‹
    5. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¯é€‰ï¼‰
    6. å¯åŠ¨è®­ç»ƒæµç¨‹
    7. å¤„ç†å¼‚å¸¸å’Œé”™è¯¯æ¢å¤
    
    å¼‚å¸¸å¤„ç†ï¼š
    - æ˜¾å­˜æº¢å‡ºï¼šè‡ªåŠ¨å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹æœºåˆ¶
    - æ¨¡å‹åŠ è½½å¤±è´¥ï¼šæä¾›æ¸…æ™°çš„é”™è¯¯ä¿¡æ¯
    - è®¾å¤‡é…ç½®é—®é¢˜ï¼šè‡ªåŠ¨å›é€€åˆ°CPU
    """
    
    # ================================
    # 1. ç¯å¢ƒåˆå§‹åŒ–
    # ================================
    # è§£æå‘½ä»¤è¡Œå‚æ•°ï¼Œè·å–è®­ç»ƒé…ç½®
    args = get_args()
    
    # é…ç½®æ—¥å¿—ç³»ç»Ÿ
    # ä½¿ç”¨INFOçº§åˆ«è®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„é‡è¦ä¿¡æ¯
    logging.basicConfig(
        level=logging.INFO, 
        format='%(asctime)s - %(levelname)s: %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # è‡ªåŠ¨æ£€æµ‹å’Œé…ç½®è®¡ç®—è®¾å¤‡
    # ä¼˜å…ˆä½¿ç”¨GPUï¼Œå¦‚æœä¸å¯ç”¨åˆ™å›é€€åˆ°CPU
    if torch.cuda.is_available():
        device = torch.device('cuda')
        logging.info(f'æ£€æµ‹åˆ°CUDAè®¾å¤‡ï¼Œä½¿ç”¨GPUè®­ç»ƒ: {torch.cuda.get_device_name()}')
        logging.info(f'GPUæ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB')
    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        device = torch.device('mps')
        logging.info('æ£€æµ‹åˆ°Apple Siliconè®¾å¤‡ï¼Œä½¿ç”¨MPSè®­ç»ƒ')
    else:
        device = torch.device('cpu')
        logging.warning('æœªæ£€æµ‹åˆ°GPUï¼Œä½¿ç”¨CPUè®­ç»ƒï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰')
    
    logging.info(f'è®­ç»ƒè®¾å¤‡: {device}')

    # ================================
    # 2. æ¨¡å‹åˆ›å»ºå’Œé…ç½®
    # ================================
    # åˆ›å»ºUNetæ¨¡å‹å®ä¾‹
    # n_channels=3: RGBå›¾åƒè¾“å…¥é€šé“æ•°
    # n_classes: åˆ†å‰²ç±»åˆ«æ•°ï¼ˆåŒ…æ‹¬èƒŒæ™¯ç±»ï¼‰
    # bilinear: æ˜¯å¦ä½¿ç”¨åŒçº¿æ€§æ’å€¼ä¸Šé‡‡æ ·
    model = UNet(
        n_channels=3, 
        n_classes=args.classes, 
        bilinear=args.bilinear
    )
    
    # é…ç½®å†…å­˜æ ¼å¼ä¼˜åŒ–
    # channels_lastæ ¼å¼å¯ä»¥æå‡GPUæ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å·ç§¯æ“ä½œä¸­
    model = model.to(memory_format=torch.channels_last)

    # æ‰“å°æ¨¡å‹ç»“æ„ä¿¡æ¯
    logging.info(f'''
    ================================
    æ¨¡å‹é…ç½®ä¿¡æ¯
    ================================
    è¾“å…¥é€šé“æ•°:         {model.n_channels} (RGBå›¾åƒ)
    è¾“å‡ºé€šé“æ•°:         {model.n_classes} (åˆ†å‰²ç±»åˆ«)
    ä¸Šé‡‡æ ·æ–¹å¼:         {"åŒçº¿æ€§æ’å€¼" if model.bilinear else "è½¬ç½®å·ç§¯"}
    æ¨¡å‹å‚æ•°é‡:         {sum(p.numel() for p in model.parameters()):,}
    å¯è®­ç»ƒå‚æ•°:         {sum(p.numel() for p in model.parameters() if p.requires_grad):,}
    ================================
    ''')

    # ================================
    # 3. é¢„è®­ç»ƒæ¨¡å‹åŠ è½½
    # ================================
    # å¦‚æœæŒ‡å®šäº†é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼Œåˆ™åŠ è½½æ¨¡å‹æƒé‡
    if args.load:
        try:
            logging.info(f'æ­£åœ¨ä» {args.load} åŠ è½½é¢„è®­ç»ƒæ¨¡å‹...')
            
            # åŠ è½½æ£€æŸ¥ç‚¹æ–‡ä»¶
            state_dict = torch.load(args.load, map_location=device)
            
            # æ¸…ç†æ•°æ®é›†ç›¸å…³çš„å‚æ•°
            # mask_valuesæ˜¯æ•°æ®é›†ç‰¹å®šçš„ï¼Œä¸å±äºæ¨¡å‹å‚æ•°
            if 'mask_values' in state_dict:
                del state_dict['mask_values']
                logging.info('å·²ç§»é™¤æ•°æ®é›†ç›¸å…³çš„mask_valueså‚æ•°')
            
            # åŠ è½½æ¨¡å‹å‚æ•°
            model.load_state_dict(state_dict, strict=False)
            logging.info('âœ… é¢„è®­ç»ƒæ¨¡å‹åŠ è½½æˆåŠŸï¼')
            
            # æ˜¾ç¤ºåŠ è½½çš„æ£€æŸ¥ç‚¹ä¿¡æ¯
            if 'epoch' in state_dict:
                logging.info(f'æ£€æŸ¥ç‚¹è½®æ¬¡: {state_dict["epoch"]}')
            if 'loss' in state_dict:
                logging.info(f'æ£€æŸ¥ç‚¹æŸå¤±: {state_dict["loss"]:.4f}')
                
        except FileNotFoundError:
            logging.error(f'âŒ æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {args.load}')
            logging.info('è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®')
            sys.exit(1)
        except Exception as e:
            logging.error(f'âŒ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹æ—¶å‡ºé”™: {str(e)}')
            logging.info('è¯·æ£€æŸ¥æ£€æŸ¥ç‚¹æ–‡ä»¶æ˜¯å¦å®Œæ•´æˆ–å…¼å®¹')
            sys.exit(1)

    # å°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ï¼ˆGPU/CPUï¼‰
    model.to(device=device)
    logging.info(f'æ¨¡å‹å·²ç§»åŠ¨åˆ°è®¾å¤‡: {device}')

    # ================================
    # 4. è®­ç»ƒæµç¨‹å¯åŠ¨
    # ================================
    try:
        logging.info('ğŸš€ å¼€å§‹è®­ç»ƒè¿‡ç¨‹...')
        
        # è°ƒç”¨ä¸»è®­ç»ƒå‡½æ•°
        train_model(
            model=model,
            epochs=args.epochs,
            batch_size=args.batch_size,
            learning_rate=args.lr,
            device=device,
            img_scale=args.scale,
            val_percent=args.val / 100,
            amp=args.amp,
            accumulate_grad_batches=args.accumulate_grad_batches
        )
        
        logging.info('ğŸ‰ è®­ç»ƒæˆåŠŸå®Œæˆï¼')
        
    except torch.cuda.OutOfMemoryError as e:
        # ================================
        # 5. æ˜¾å­˜æº¢å‡ºå¼‚å¸¸å¤„ç†
        # ================================
        logging.error('âš ï¸ æ£€æµ‹åˆ°GPUæ˜¾å­˜æº¢å‡ºï¼æ­£åœ¨é‡‡å–è¡¥æ•‘æªæ–½...')
        
        # æ¸…ç†CUDAç¼“å­˜ï¼Œé‡Šæ”¾æœªä½¿ç”¨çš„æ˜¾å­˜
        logging.info('1. æ¸…ç†CUDAç¼“å­˜...')
        torch.cuda.empty_cache()
        
        # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹æœºåˆ¶
        # è¿™ä¼šç”¨è®¡ç®—æ—¶é—´æ¢å–æ˜¾å­˜ç©ºé—´ï¼Œé€‚ç”¨äºå¤§æ¨¡å‹è®­ç»ƒ
        logging.info('2. å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹æœºåˆ¶(gradient checkpointing)...')
        model.use_checkpointing()
        
        # æä¾›ä¼˜åŒ–å»ºè®®
        logging.warning('''
        ================================
        æ˜¾å­˜ä¼˜åŒ–å»ºè®®
        ================================
        å½“å‰é…ç½®å¯èƒ½è¶…å‡ºGPUæ˜¾å­˜é™åˆ¶ï¼Œå»ºè®®ï¼š
        
        1. å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼š
           python train.py --amp
        
        2. å‡å°æ‰¹æ¬¡å¤§å°ï¼š
           python train.py --batch-size 1
        
        3. å‡å°è¾“å…¥å›¾åƒå°ºå¯¸ï¼š
           python train.py --scale 0.25
        
        4. ä½¿ç”¨åŒçº¿æ€§ä¸Šé‡‡æ ·ï¼š
           python train.py --bilinear
        
        5. ç»„åˆä¼˜åŒ–ï¼š
           python train.py --amp --batch-size 1 --scale 0.25 --bilinear
        ================================
        ''')
        
        # é‡æ–°å°è¯•è®­ç»ƒ
        logging.info('3. ä½¿ç”¨ä¼˜åŒ–åçš„è®¾ç½®é‡æ–°è®­ç»ƒ...')
        train_model(
            model=model,
            epochs=args.epochs,
            batch_size=max(1, args.batch_size // 2),  # å‡å°æ‰¹æ¬¡å¤§å°
            learning_rate=args.lr,
            device=device,
            img_scale=min(0.25, args.scale),  # å‡å°å›¾åƒå°ºå¯¸
            val_percent=args.val / 100,
            amp=True,  # å¼ºåˆ¶å¯ç”¨æ··åˆç²¾åº¦
            accumulate_grad_batches=max(2, args.accumulate_grad_batches)  # å¢åŠ æ¢¯åº¦ç´¯ç§¯
        )
        
    except KeyboardInterrupt:
        logging.info('â¹ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­')
        logging.info('ğŸ’¡ æç¤ºï¼šå¯ä»¥ä»æœ€æ–°ä¿å­˜çš„æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ')
        
    except Exception as e:
        logging.error(f'âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {str(e)}')
        logging.error('è¯·æ£€æŸ¥æ•°æ®è·¯å¾„ã€æ¨¡å‹é…ç½®å’Œç³»ç»Ÿç¯å¢ƒ')
        raise e
    
    finally:
        # æ¸…ç†èµ„æº
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        logging.info('ğŸ”§ èµ„æºæ¸…ç†å®Œæˆ')
