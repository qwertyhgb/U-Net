# PyTorch UNet 项目运行参数指南

## 📋 目录
- [项目概述](#项目概述)
- [环境要求](#环境要求)
- [训练参数](#训练参数)
- [预测参数](#预测参数)
- [硬件配置推荐](#硬件配置推荐)
- [使用示例](#使用示例)
- [故障排除](#故障排除)

## 🎯 项目概述

本项目是基于PyTorch实现的U-Net图像分割模型，专门用于医学图像分割、卫星图像分割等任务。支持多种训练配置和优化策略。

### 主要特性
- ✅ 支持二分类和多分类分割任务
- ✅ 自动混合精度训练（AMP）加速
- ✅ **梯度累积支持**，模拟大批次训练
- ✅ **智能梯度检查点**，自动显存优化
- ✅ WandB实验跟踪和可视化
- ✅ 自动检查点保存和恢复
- ✅ 梯度裁剪和学习率调度
- ✅ 早停机制防止过拟合
- ✅ 显存优化和异常处理
- ✅ **非阻塞数据传输**，提升训练速度

## 🔧 环境要求

### 依赖安装
```bash
pip install -r requirements.txt
```

### 主要依赖版本
- `torch==2.0.0`
- `torchvision==0.15.0`
- `numpy==1.24.3`
- `matplotlib==3.7.5`
- `Pillow==10.3.0`
- `tqdm==4.66.4`

## 🚀 训练参数详解

### 基础训练参数

| 参数 | 短参数 | 类型 | 默认值 | 说明 |
|------|--------|------|--------|------|
| `--epochs` | `-e` | int | 5 | 训练轮数 |
| `--batch-size` | `-b` | int | 1 | 每批次样本数 |
| `--learning-rate` | `-l` | float | 1e-5 | 初始学习率 |
| `--load` | `-f` | str | False | 预训练模型路径 |
| `--scale` | `-s` | float | 0.5 | 图像缩放因子(0-1) |
| `--validation` | `-v` | float | 10.0 | 验证集比例(0-100) |
| `--classes` | `-c` | int | 2 | 分割类别数 |

### 优化参数

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| `--amp` | bool | False | 启用混合精度训练 |
| `--bilinear` | bool | False | 使用双线性插值上采样 |
| `--accumulate-grad-batches` | int | 1 | **梯度累积批次数** |

### 🆕 新增功能说明

#### 梯度累积 (Gradient Accumulation)
- **作用**：模拟更大的批次大小，在显存受限时特别有用
- **原理**：累积多个小批次的梯度后再更新参数
- **有效批次大小** = `batch_size` × `accumulate_grad_batches`
- **示例**：`--batch-size 2 --accumulate-grad-batches 4` 等效于批次大小为8

### 参数推荐值

#### 📊 训练轮数 (epochs)
```bash
# 小数据集：50-100轮
--epochs 80

# 大数据集：20-50轮  
--epochs 30
```

#### 📦 批次大小 (batch-size)
```bash
# 根据GPU显存调整
8GB显存:  --batch-size 4-8
16GB显存: --batch-size 8-16
32GB显存: --batch-size 16-32
```

#### 🎯 学习率 (learning-rate)
```bash
# 推荐范围：1e-4 到 1e-6
--learning-rate 1e-4    # 标准学习率
--learning-rate 5e-5    # 保守学习率
--learning-rate 1e-5    # 精细调优
```

#### 🖼️ 图像缩放 (scale)
```bash
--scale 1.0    # 原始尺寸，最佳精度，需要更多显存
--scale 0.75   # 平衡性能和精度
--scale 0.5    # 默认值，节省显存
--scale 0.25   # 最小显存占用
```

#### ✅ 验证集比例 (validation)
```bash
--validation 10    # 大数据集推荐
--validation 20    # 中等数据集推荐  
--validation 30    # 小数据集推荐
```

## 🎯 预测参数详解

### 基本语法
```bash
python predict.py [参数选项]
```

### 预测参数表

| 参数 | 短参数 | 类型 | 默认值 | 说明 |
|------|--------|------|--------|------|
| `--model` | `-m` | str | MODEL.pth | 模型文件路径 |
| `--input` | `-i` | str | 必需 | 输入图片路径 |
| `--output` | `-o` | str | 自动生成 | 输出图片路径 |
| `--scale` | `-s` | float | 0.5 | 图像缩放因子 |
| `--mask-threshold` | `-t` | float | 0.5 | 掩码二值化阈值 |
| `--classes` | `-c` | int | 2 | 分割类别数 |
| `--bilinear` | - | bool | False | 使用双线性上采样 |
| `--viz` | `-v` | bool | False | 可视化结果 |
| `--no-save` | `-n` | bool | False | 不保存输出掩码 |

## 💻 硬件配置推荐

### GPU配置方案

#### 🟢 入门级配置 (4-6GB显存)
```bash
python train.py \
    --epochs 50 \
    --batch-size 1 \
    --learning-rate 1e-4 \
    --amp \
    --scale 0.25 \
    --bilinear \
    --accumulate-grad-batches 8
```
**有效批次大小**: 8 (1×8)

#### 🟡 主流配置 (8-12GB显存)
```bash
python train.py \
    --epochs 80 \
    --batch-size 4 \
    --learning-rate 1e-4 \
    --amp \
    --scale 0.5 \
    --accumulate-grad-batches 2
```
**有效批次大小**: 8 (4×2)

#### 🔴 高端配置 (16GB+显存)
```bash
python train.py \
    --epochs 100 \
    --batch-size 8 \
    --learning-rate 1e-4 \
    --amp \
    --scale 0.75 \
    --accumulate-grad-batches 2
```
**有效批次大小**: 16 (8×2)

#### ⚪ CPU训练
```bash
python train.py \
    --epochs 30 \
    --batch-size 1 \
    --learning-rate 1e-4 \
    --accumulate-grad-batches 4
```
**有效批次大小**: 4 (1×4)

## 📝 使用示例

### 基础训练示例

#### 1. 快速开始训练
```bash
# 使用默认参数进行训练
python train.py

# 基础自定义训练
python train.py --epochs 50 --batch-size 8 --learning-rate 1e-4
```

#### 2. 高性能训练
```bash
# 混合精度 + 梯度累积训练
python train.py \
    --epochs 100 \
    --batch-size 8 \
    --learning-rate 1e-4 \
    --amp \
    --scale 0.75 \
    --validation 20 \
    --accumulate-grad-batches 2
```

#### 3. 从检查点恢复训练
```bash
# 从指定检查点恢复
python train.py \
    --load checkpoints/checkpoint_epoch10.pth \
    --epochs 50 \
    --batch-size 8
```

#### 4. 多分类分割任务
```bash
# 5分类分割任务
python train.py \
    --classes 5 \
    --epochs 80 \
    --batch-size 4 \
    --learning-rate 1e-4 \
    --amp \
    --accumulate-grad-batches 2
```

#### 5. 🆕 梯度累积训练示例
```bash
# 小显存模拟大批次训练
python train.py \
    --epochs 80 \
    --batch-size 1 \
    --learning-rate 1e-4 \
    --amp \
    --accumulate-grad-batches 16 \
    --scale 0.5
```
**说明**: 有效批次大小为16，适合显存不足但需要大批次训练的场景

### 预测示例

#### 1. 单张图片预测
```bash
python predict.py \
    --model checkpoints/checkpoint_epoch50.pth \
    --input test_image.jpg \
    --output result.png
```

#### 2. 批量预测（可视化）
```bash
python predict.py \
    --model checkpoints/best_model.pth \
    --input image1.jpg image2.jpg image3.jpg \
    --viz \
    --no-save
```

#### 3. 自定义参数预测
```bash
python predict.py \
    --model best_model.pth \
    --input test.jpg \
    --output result.png \
    --scale 0.75 \
    --mask-threshold 0.3 \
    --classes 3
```

### 特定任务配置

#### 🏥 医学图像分割
```bash
python train.py \
    --epochs 80 \
    --batch-size 2 \
    --learning-rate 1e-4 \
    --amp \
    --validation 25 \
    --scale 0.5 \
    --accumulate-grad-batches 4
```
**有效批次大小**: 8，适合精细的医学图像分割

#### 🛰️ 卫星图像分割
```bash
python train.py \
    --epochs 60 \
    --batch-size 4 \
    --learning-rate 1e-4 \
    --amp \
    --scale 0.75 \
    --validation 15 \
    --accumulate-grad-batches 2
```
**有效批次大小**: 8，平衡速度和精度

#### 🔬 生物图像分析
```bash
python train.py \
    --epochs 100 \
    --batch-size 2 \
    --learning-rate 1e-5 \
    --amp \
    --validation 20 \
    --scale 0.5 \
    --accumulate-grad-batches 3
```
**有效批次大小**: 6，适合小样本生物图像

## ⚠️ 故障排除

### 常见问题及解决方案

#### 🚨 显存不足 (CUDA Out of Memory)

**问题症状：**
```
RuntimeError: CUDA out of memory
```

**解决方案：**
```bash
# 方案1：启用混合精度训练
python train.py --amp

# 方案2：减小批次大小 + 梯度累积
python train.py --batch-size 1 --accumulate-grad-batches 8

# 方案3：降低图像分辨率
python train.py --scale 0.25

# 方案4：使用双线性插值减少参数量
python train.py --bilinear

# 方案5：🆕 终极优化组合（推荐）
python train.py \
    --amp \
    --batch-size 1 \
    --scale 0.25 \
    --bilinear \
    --accumulate-grad-batches 8
```
**说明**: 方案5通过梯度累积保持有效批次大小为8，同时最大化显存节省

#### 🔍 训练不收敛

**可能原因和解决方案：**

1. **学习率过高**
```bash
# 降低学习率
python train.py --learning-rate 1e-5
```

2. **有效批次大小过小**
```bash
# 方案A：增加物理批次大小（在显存允许的情况下）
python train.py --batch-size 8

# 方案B：🆕 使用梯度累积增加有效批次大小
python train.py --batch-size 2 --accumulate-grad-batches 4
```

3. **数据不足**
```bash
# 增加验证集比例，确保数据划分合理
python train.py --validation 20
```

#### 📉 验证分数低

**优化策略：**
```bash
# 1. 增加训练轮数
python train.py --epochs 100

# 2. 调高图像分辨率
python train.py --scale 0.75

# 3. 调整学习率
python train.py --learning-rate 5e-5
```

### 性能优化建议

#### 🚀 训练加速
```bash
# 启用所有优化选项
python train.py \
    --amp \
    --batch-size 8 \
    --scale 0.75 \
    --epochs 80 \
    --accumulate-grad-batches 2
```

#### 💾 显存优化
```bash
# 🆕 极限显存优化（保持训练效果）
python train.py \
    --amp \
    --bilinear \
    --batch-size 1 \
    --scale 0.25 \
    --accumulate-grad-batches 16
```
**说明**: 有效批次大小为16，在极限显存下保持良好的训练效果

### 监控和调试

#### 📊 WandB监控
项目已集成WandB，训练过程中会自动：
- 记录训练和验证损失
- 可视化权重和梯度分布
- 显示预测结果对比
- 跟踪学习率变化

#### 🔧 日志和检查点
- 训练日志：实时显示训练进度
- 检查点保存：`checkpoints/checkpoint_epoch{N}.pth`
- 自动恢复：支持从任意检查点恢复训练

## 📚 参数选择指南

### 根据数据集大小选择参数

#### 小数据集 (< 1000张)
```bash
python train.py \
    --epochs 100 \
    --batch-size 2 \
    --learning-rate 1e-4 \
    --validation 30 \
    --accumulate-grad-batches 4
```
**有效批次大小**: 8，避免过拟合

#### 中等数据集 (1000-10000张)
```bash
python train.py \
    --epochs 80 \
    --batch-size 4 \
    --learning-rate 1e-4 \
    --validation 20 \
    --accumulate-grad-batches 2
```
**有效批次大小**: 8，平衡训练效率

#### 大数据集 (> 10000张)
```bash
python train.py \
    --epochs 50 \
    --batch-size 8 \
    --learning-rate 1e-4 \
    --validation 10 \
    --accumulate-grad-batches 2
```
**有效批次大小**: 16，充分利用数据

### 根据任务类型调整参数

#### 精细分割任务
```bash
python train.py \
    --scale 0.75 \
    --learning-rate 5e-5 \
    --validation 25 \
    --batch-size 2 \
    --accumulate-grad-batches 4
```
**有效批次大小**: 8，保证精细分割质量

#### 快速原型验证
```bash
python train.py \
    --epochs 20 \
    --batch-size 4 \
    --scale 0.25 \
    --amp \
    --accumulate-grad-batches 2
```
**有效批次大小**: 8，快速验证想法

## 🔬 高级优化功能详解

### 梯度累积 (Gradient Accumulation)

#### 工作原理
```python
# 传统训练：每个批次都更新参数
for batch in dataloader:
    loss = model(batch)
    loss.backward()
    optimizer.step()  # 每次都更新
    optimizer.zero_grad()

# 梯度累积：累积多个批次后再更新
accumulate_steps = 4
for i, batch in enumerate(dataloader):
    loss = model(batch) / accumulate_steps  # 缩放损失
    loss.backward()
    
    if (i + 1) % accumulate_steps == 0:
        optimizer.step()  # 每4个批次更新一次
        optimizer.zero_grad()
```

#### 使用场景
- **显存不足**：无法使用大批次时
- **分布式训练**：模拟更大的全局批次
- **稳定训练**：大批次通常训练更稳定

#### 参数选择指南
```bash
# 显存充足：直接使用大批次
--batch-size 16 --accumulate-grad-batches 1

# 显存不足：梯度累积模拟大批次
--batch-size 2 --accumulate-grad-batches 8  # 等效批次大小16

# 极限显存：最小批次 + 大累积
--batch-size 1 --accumulate-grad-batches 16  # 等效批次大小16
```

### 智能显存优化

#### 自动梯度检查点
当检测到显存不足时，系统会自动启用梯度检查点：
```bash
# 显存溢出时自动启用
⚠️ 检测到GPU显存溢出！正在采取补救措施...
2. 启用梯度检查点机制(gradient checkpointing)...
```

#### 内存格式优化
- **CUDA设备**：自动使用 `channels_last` 内存格式
- **CPU/MPS设备**：使用标准连续内存格式
- **非阻塞传输**：GPU训练时启用 `non_blocking=True`

### 训练策略组合

#### 🎯 推荐组合策略

| 显存大小 | 批次大小 | 累积步数 | 有效批次 | 其他优化 |
|---------|---------|---------|---------|---------|
| 4GB | 1 | 16 | 16 | `--amp --bilinear --scale 0.25` |
| 8GB | 2 | 4 | 8 | `--amp --scale 0.5` |
| 12GB | 4 | 2 | 8 | `--amp --scale 0.75` |
| 16GB+ | 8 | 2 | 16 | `--amp --scale 0.75` |

#### 🚀 性能优化技巧

1. **数据加载优化**
   ```bash
   # 多进程数据加载（根据CPU核心数自动调整）
   # 锁页内存（仅CUDA设备）
   # 持久化worker进程
   ```

2. **混合精度训练**
   ```bash
   # 自动检测设备支持
   # CUDA: 启用FP16
   # CPU/MPS: 自动禁用
   --amp
   ```

3. **学习率调度**
   ```bash
   # 余弦退火重启
   # 自动调整最小学习率
   # 根据验证分数动态调整
   ```

### 🔧 调试和监控

#### WandB集成功能
- **实时损失曲线**：训练和验证损失
- **学习率跟踪**：动态学习率变化
- **梯度分布**：权重和梯度直方图
- **预测可视化**：输入图像、真实掩码、预测掩码对比
- **硬件监控**：GPU利用率、显存使用

#### 早停机制
```python
# 自动早停配置
patience = 10        # 连续10轮无改善则停止
min_delta = 0.001   # 最小改善阈值
restore_best_weights = True  # 恢复最佳权重
```

#### 检查点管理
```bash
# 自动保存
checkpoints/checkpoint_epoch{N}.pth  # 每轮检查点
checkpoints/best_model.pth          # 最佳模型

# 恢复训练
--load checkpoints/checkpoint_epoch10.pth
```

---

## 📞 技术支持

### 常见问题快速诊断

#### 🔍 问题诊断清单
1. **数据路径**：确认 `data/imgs/` 和 `data/masks/` 存在且包含数据
2. **硬件兼容**：GPU驱动和CUDA版本是否兼容
3. **依赖版本**：检查 `requirements.txt` 中的包版本
4. **显存使用**：使用 `nvidia-smi` 监控GPU显存
5. **训练日志**：查看详细的错误信息和警告

#### 🚨 紧急救援命令
```bash
# 显存严重不足时的最小配置
python train.py \
    --batch-size 1 \
    --accumulate-grad-batches 16 \
    --scale 0.25 \
    --amp \
    --bilinear \
    --epochs 50

# 快速验证数据和代码
python train.py \
    --epochs 2 \
    --batch-size 1 \
    --scale 0.25 \
    --validation 50
```

#### 📊 性能基准参考

| 配置 | 训练速度 | 显存占用 | 推荐场景 |
|------|---------|---------|---------|
| `batch=1, acc=1` | 慢 | 最低 | 调试/测试 |
| `batch=1, acc=8` | 中等 | 低 | 显存不足 |
| `batch=4, acc=2` | 快 | 中等 | 平衡配置 |
| `batch=8, acc=2` | 最快 | 高 | 高端GPU |

### 🎯 最佳实践总结

1. **从小开始**：先用小配置验证代码和数据
2. **逐步优化**：根据硬件能力逐步增加批次大小
3. **监控训练**：使用WandB观察训练曲线
4. **保存检查点**：定期保存，避免训练中断损失
5. **梯度累积**：显存不足时的最佳选择

**祝您训练顺利！** 🎉

---

## 📈 版本更新日志

### v2.0 (最新)
- ✅ 新增梯度累积支持
- ✅ 智能梯度检查点
- ✅ 非阻塞数据传输
- ✅ 设备自适应优化
- ✅ 增强的异常处理

### v1.0
- ✅ 基础UNet训练功能
- ✅ 混合精度训练
- ✅ WandB集成
- ✅ 自动检查点保存
